{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A4HuVIYGgXg"
      },
      "source": [
        "# Notebook Processo Seletivo Aluno Especial IA-024 1S2024 FEEC-UNICAMP\n",
        "versão 5 de fevereiro de 2024, 19h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA5BWLDCKmw3",
        "outputId": "de1d4b42-dd18-4605-d09b-ad3e22f27475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "!pip install 'portalocker>=2.0.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VorDvF62iyXF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.datasets import IMDB\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dTophXo7E1W-"
      },
      "outputs": [],
      "source": [
        "# Parâmetros gerais de execução do Notebook\n",
        "# Uso do Tokenizador\n",
        "use_tokenizer = True\n",
        "\n",
        "# Preloading data\n",
        "preload_to_gpu = True\n",
        "\n",
        "# Learning Rate\n",
        "best_LR = 0.1\n",
        "\n",
        "# Shuffle Dataloader (treinamento)\n",
        "train_shuffle = True\n",
        "\n",
        "# Número de amostras usadas\n",
        "n_samples = 25000\n",
        "\n",
        "# Balanceamento do dataset\n",
        "balance_dataset = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ovJE02CwKT"
      },
      "source": [
        "## I - Vocabulário e Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqzUqy3diz0X",
        "outputId": "5e1c7308-91c3-4317-acca-da4dee6acfbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras positivas, negativas e totais:\n",
            "Counter({'total': 25000, 'pos': 12500, 'neg': 12500})\n",
            "\n",
            "Comprimento médio do texto em palavras\n",
            "270.68748\n",
            "\n",
            "Cinco palavras mais frequentes:\n",
            "['the', '.', ',', 'and', 'a']\n",
            "\n",
            "Cinco palavras menos frequentes:\n",
            "['voicing', 'hazard', 'lynda', 'gft', 'watergate']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# limit the vocabulary size to 20000 most frequent tokens\n",
        "vocab_size = 20000\n",
        "\n",
        "# I.1. Na célula de calcular o vocabulário, aproveite o laço sobre IMDB de treinamento e utilize um segundo contador\n",
        "# para calcular o número de amostras positivas e amostras negativas.\n",
        "# Calcule também o comprimento médio do texto em número de palavras dos textos das amostras.\n",
        "\n",
        "counter = Counter()\n",
        "counter_lbl = Counter({\"pos\": 0, \"neg\": 0, \"total\": 0})\n",
        "total_review_len = 0\n",
        "avg_review_len = 0\n",
        "\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "    if (use_tokenizer):\n",
        "      tokenizer = get_tokenizer('basic_english')\n",
        "      # tokenize the sentence\n",
        "      line = tokenizer(line)\n",
        "      counter.update(line)\n",
        "    else:\n",
        "      counter.update(line.split())\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    if (use_tokenizer):\n",
        "      total_review_len += len(line)\n",
        "    else:\n",
        "      total_review_len += len(line.split())\n",
        "\n",
        "# Comprimento médio\n",
        "avg_review_len = total_review_len / counter_lbl['total']\n",
        "\n",
        "# I.2 Mostre as cinco palavras mais frequentes do vocabulário e as cinco palavras menos frequentes.\n",
        "# Qual é o código do token que está sendo utilizado quando a palavra não está no vocabulário?\n",
        "# Calcule quantos tokens das frases do conjunto de treinamento que não estão no vocabulário.\n",
        "\n",
        "# create a vocabulary of the 20000 most frequent tokens\n",
        "most_frequent_words = sorted(counter, key=counter.get, reverse=True)[:vocab_size]\n",
        "vocab = {word: i for i, word in enumerate(most_frequent_words, 1)} # words indexed from 1 to 20000\n",
        "vocab_size = len(vocab) #Errata\n",
        "\n",
        "print(\"Amostras positivas, negativas e totais:\")\n",
        "print(counter_lbl)\n",
        "print()\n",
        "\n",
        "print(\"Comprimento médio do texto em palavras\")\n",
        "print(avg_review_len)\n",
        "print()\n",
        "\n",
        "print(\"Cinco palavras mais frequentes:\")\n",
        "print(most_frequent_words[:5])\n",
        "print()\n",
        "\n",
        "print(\"Cinco palavras menos frequentes:\")\n",
        "print(most_frequent_words[-5:])\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rZn-m1Mi110",
        "outputId": "32a3676e-fd70-4848-8855-c2ef8277fbef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de tokens que não estão no vocabulário na base de treinamento:\n",
            "174226\n"
          ]
        }
      ],
      "source": [
        "# I.2 Calcule quantos tokens das frases do conjunto de treinamento que não estão no vocabulário.\n",
        "\n",
        "def encode_sentence(sentence, vocab, use_tokenizer):\n",
        "    if (use_tokenizer):\n",
        "       sentence = tokenizer(sentence)\n",
        "       return [vocab.get(word, 0) for word in sentence]\n",
        "    else:\n",
        "      return [vocab.get(word, 0) for word in sentence.split()] # 0 for OOV\n",
        "\n",
        "encode_sentence(\"I like Pizza\", vocab, use_tokenizer)\n",
        "\n",
        "# Cálculo do número de tokens que não estão no vocabulário na base de treinamento:\n",
        "tokens = []\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "  tokens.extend(encode_sentence(line, vocab, use_tokenizer))\n",
        "\n",
        "print(\"Número de tokens que não estão no vocabulário na base de treinamento:\")\n",
        "print(tokens.count(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7tJ5XHQS7g6"
      },
      "source": [
        "#### I.2 Qual é o código do token que está sendo utilizado quando a palavra não está no vocabulário?\n",
        "\n",
        "Na função de dicionário dict.get() o segundo parâmetro indica o valor default caso a palavra não seja encontrada no dicionário. Nesse caso o código do token usado é o número zero.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri9lyeL_zx-1"
      },
      "source": [
        "#### I.3.a) Qual é a razão pela qual o modelo preditivo conseguiu acertar 100% das amostras de teste do dataset selecionado com apenas as primeiras 200 amostras?\n",
        "\n",
        "Ao reduzirmos a base de treinamento para apenas 200 amostras, a base se tornou totalmente desbalanceada. Como pudemos verificar, temos 200 amostras classificadas como negativas e nenhuma como positiva.\n",
        "Portanto a taxa de acurácia calculada sobre a classificação da base de testes depende unicamente da percentagem de amostras positivas ou negativas nesta base.\n",
        "\n",
        "#### I.3.b) Modifique a forma de selecionar 200 amostras do dataset, porém garantindo que ele continue balanceado, isto é, aproximadamente 100 amostras positivas e 100 amostras negativas.\n",
        "\n",
        "Para obtermos um dataset balanceado, usaremos uma função que seleciona amostras do dataset de acordo com a classificação e cria um dataset com a quantidade de amostras de cada classificação desejada conforme abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwYM7hAGBCeQ",
        "outputId": "293e98d5-0c8c-4ba1-d9df-c3dfee5d3bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comprimento médio do texto em palavras na base balanceada\n",
            "270.68748\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Função para selecionar dados balanceados\n",
        "from random import shuffle\n",
        "\n",
        "def balanced_dataset(data, size):\n",
        "  if (balance_dataset):\n",
        "    data_pos = [(label,line) for label, line in data if label == 2][:int(size/2)]\n",
        "    data_neg = [(label,line) for label, line in data if label == 1][:int(size/2)]\n",
        "\n",
        "    data_bal = data_pos + data_neg\n",
        "    shuffle(data_bal)\n",
        "\n",
        "    return data_bal\n",
        "  else:\n",
        "     return data\n",
        "\n",
        "# Aplicando sobre a base de treinamento\n",
        "\n",
        "train_data = IMDB(split='train')\n",
        "counter = Counter()\n",
        "total_review_len = 0\n",
        "avg_review_len = 0\n",
        "\n",
        "for (label, line) in list(balanced_dataset(train_data, n_samples)):\n",
        "    counter.update(line.split())\n",
        "\n",
        "    # Comprimento médio do texto das reviews em palavras\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    # tokenize the sentence\n",
        "    tokens = tokenizer(line)\n",
        "\n",
        "    # count the number of words\n",
        "    total_review_len += len(tokens)\n",
        "\n",
        "# Comprimento médio\n",
        "avg_review_len = total_review_len / n_samples\n",
        "\n",
        "print(\"Comprimento médio do texto em palavras na base balanceada\")\n",
        "print(avg_review_len)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iV4bF8cDAj1"
      },
      "source": [
        "## II - Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VDUyZoTPi262"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import one_hot\n",
        "# Dataset Class with One-hot Encoding\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, split, vocab):\n",
        "\n",
        "        # II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "        self.data = list(balanced_dataset(IMDB(split='train'), n_samples))\n",
        "\n",
        "        if preload_to_gpu:\n",
        "          labels = [x[0] for x in self.data]\n",
        "          lines = [x[1] for x in self.data]\n",
        "\n",
        "          # One-Hot Encoding\n",
        "          self.labels_enc = []\n",
        "          for l in labels:\n",
        "            l = 1 if l == 1 else 0\n",
        "            self.labels_enc.append(l)\n",
        "          self.labels_enc = torch.tensor(self.labels_enc)\n",
        "          self.labels_enc = self.labels_enc.to(device)\n",
        "\n",
        "          self.lines_enc = []\n",
        "          for l in lines:\n",
        "            X = torch.zeros(len(vocab) + 1)\n",
        "\n",
        "            for word in encode_sentence(l, vocab, use_tokenizer):\n",
        "              X[word] = 1\n",
        "            self.lines_enc.append(X)\n",
        "          self.lines_enc = [tensor.to(device) for tensor in self.lines_enc]\n",
        "\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not preload_to_gpu:\n",
        "          label, line = self.data[idx]\n",
        "          label = 1 if label == 1 else 0\n",
        "\n",
        "          # one-hot encoding\n",
        "          X = torch.zeros(len(self.vocab) + 1)\n",
        "\n",
        "          for word in encode_sentence(line, self.vocab, use_tokenizer):\n",
        "              X[word] = 1\n",
        "\n",
        "          return X, torch.tensor(label)\n",
        "        else:\n",
        "          return self.lines_enc[idx], self.labels_enc[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqXuAWR0E1XA",
        "outputId": "c8ec5c0b-e7b0-4cda-f240-6519babcae16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras positivas, negativas e totais:\n",
            "Counter({'total': 25000, 'pos': 12500, 'neg': 12500})\n",
            "\n",
            "Quantidade média de palavras codificadas em cada vetor one-hot\n",
            "139.59268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load Data with One-hot Encoding\n",
        "train_data = IMDBDataset('train', vocab)\n",
        "test_data = IMDBDataset('test', vocab)\n",
        "\n",
        "# II.1.a) Investigue o dataset criado na linha 24. Faça um código que aplique um laço sobre o dataset train_data\n",
        "# e calcule novamente quantas amostras positivas e negativas do dataset.\n",
        "# II.1.b) Calcule também o número médio de palavras codificadas em cada vetor one-hot.\n",
        "# Compare este valor com o comprimento médio de cada texto (contado em palavras), conforme calculado no exercício\n",
        "\n",
        "counter_lbl = Counter({\"pos\": 0, \"neg\": 0, \"total\": 0})\n",
        "words_encoded = 0\n",
        "for (oneHot, sentiment) in train_data:\n",
        "\n",
        "    words = oneHot.tolist()\n",
        "    label = sentiment.item()\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    hot_encoded = sum(words[i] for i in range(len(words)) if words[i] != 0)\n",
        "    words_encoded +=  hot_encoded\n",
        "\n",
        "avg_words_enc = words_encoded / counter_lbl['total']\n",
        "\n",
        "print(\"Amostras positivas, negativas e totais:\")\n",
        "print(counter_lbl)\n",
        "print()\n",
        "\n",
        "print(\"Quantidade média de palavras codificadas em cada vetor one-hot\")\n",
        "print(avg_words_enc)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdM6ojduRqrw"
      },
      "source": [
        "#### II.1.b Compare este valor com o comprimento médio de cada texto (contado em palavras), conforme calculado no exercício I.1.c. e explique a diferença.\n",
        "\n",
        "No exercício I.1.c, o comprimento médio do texto em palavras depois de passar pelo tokenizador foi de cerca de 270 palavras. Essa diferença do vetor One-Hot se deve ao fato que o vetor one-hot só codifica as palavras que foram identificadas no dicionário, enquanto que o comprimento médio considera todas as palavras das sentenças. Ou seja, palavras que não foram codificadas no dicionário serão representadas por zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7RMPSvMDL5U"
      },
      "source": [
        "## III - Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Y7tcZv2YDIog"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "# define dataloaders\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=train_shuffle)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwPeJ7h8DahT"
      },
      "source": [
        "## IV - Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6QuDhWvji7lt"
      },
      "outputs": [],
      "source": [
        "class OneHotMLP(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(OneHotMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(vocab_size+1, 200)\n",
        "        self.fc2 = nn.Linear(200, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        o = self.fc1(x.float())\n",
        "        o = self.relu(o)\n",
        "        return self.fc2(o)\n",
        "\n",
        "# Model instantiation\n",
        "model = OneHotMLP(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVAhdFGXDepU"
      },
      "source": [
        "## V - Laço de Treinamento - Otimização da função de Perda pelo Gradiente descendente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaH1Uv3yHih5",
        "outputId": "7337212a-07ed-4683-bea9-59e3de833472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "else:\n",
        "    print('using CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh_pe8rni93_",
        "outputId": "eb07b887-d41a-426c-bec7-f0e6047ed110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5],               Loss: 0.3477,               Elapsed Time: 0.51 sec\n",
            "Epoch [2/5],               Loss: 0.4754,               Elapsed Time: 0.40 sec\n",
            "Epoch [3/5],               Loss: 0.3811,               Elapsed Time: 0.38 sec\n",
            "Epoch [4/5],               Loss: 0.2097,               Elapsed Time: 0.39 sec\n",
            "Epoch [5/5],               Loss: 0.2222,               Elapsed Time: 0.38 sec\n"
          ]
        }
      ],
      "source": [
        "# II.2 Com a o notebook configurado para GPU T4, meça o tempo de dois laços dentro do\n",
        "# for da linha 13 (coloque um break após dois laços) e determine quanto demora\n",
        "# demora para o passo de forward (linhas 14 a 18), para o backward (linhas 20, 21 e 22)\n",
        "# e o tempo total de um laço. Faça as contas e identifique o trecho que é mais demorado.\n",
        "# II.2.a) Tempo do laço = ; Tempo do forward = ;Tempo do backward = ; Conclusão.\n",
        "\n",
        "import time\n",
        "\n",
        "# Transformando em função o treinamento\n",
        "def train_mdl(model, lr):\n",
        "  # Debug\n",
        "  print_loop = False\n",
        "\n",
        "  model = model.to(device)\n",
        "  # Define loss and optimizer\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 5\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      start_time = time.time()  # Start time of the epoch\n",
        "      model.train()\n",
        "\n",
        "      loop_count = 0\n",
        "\n",
        "      for inputs, labels in train_loader:\n",
        "          loop_start = time.time()\n",
        "          if(loop_count == 2 and print_loop):\n",
        "            # Para medição do tempo do loop.\n",
        "            break\n",
        "\n",
        "          forward_start = time.time()\n",
        "\n",
        "          if not preload_to_gpu:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "          gpu_cpy_time = time.time() - forward_start\n",
        "          # Forward pass\n",
        "          model_start = time.time()\n",
        "          outputs = model(inputs)\n",
        "          model_time = time.time() - model_start\n",
        "          loss = criterion(outputs.squeeze(), labels.float())\n",
        "          forward_time = time.time() - forward_start\n",
        "\n",
        "          # Backward and optimize\n",
        "          backward_start = time.time()\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          backward_time = time.time() - backward_start\n",
        "\n",
        "          # Loop optimization\n",
        "          loop_count += 1\n",
        "          loop_time = time.time() - loop_start\n",
        "          if (epoch == 0 and print_loop):\n",
        "            print(\"Loop #\", loop_count)\n",
        "            print(\"Tempo de loop = \", loop_time)\n",
        "            print(\"Forward pass = \", forward_time)\n",
        "            gpu_percent = gpu_cpy_time/forward_time\n",
        "            print(\"Gpu copy = \" + str(gpu_percent*100) + \" %\")\n",
        "            print(\"Model processing = \" + str((1 - gpu_percent)*100) + \" %\")\n",
        "            print(\"Backward pass = \", backward_time)\n",
        "            print()\n",
        "\n",
        "      end_time = time.time()  # End time of the epoch\n",
        "      epoch_duration = end_time - start_time  # Duration of epoch\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
        "              Loss: {loss.item():.4f}, \\\n",
        "              Elapsed Time: {epoch_duration:.2f} sec')\n",
        "\n",
        "# Primeiro treinamento com a melhor taxa de Learning Rate\n",
        "model = OneHotMLP(vocab_size)\n",
        "train_mdl(model, best_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBswOILbX39h"
      },
      "source": [
        "##### II.2.a) Medição dos tempos de loop\n",
        "\n",
        "Notamos que o tempo do passo do forward leva mais tempo que o passo de backward, conforme os dados obtidos abaixo para a primeira época do treinamento.\n",
        "Também notamos que a maior parte to tempo do loop de forward é gasto com a transferência dos dados da CPU para a GPU (97% no primeiro loop).\n",
        "\n",
        "**Para 200 amostras**:\n",
        "\n",
        "```\n",
        "Loop # 1\n",
        "Tempo de loop =  0.048320770263671875\n",
        "Forward pass =  0.047322750091552734\n",
        "Gpu copy = 97.88851606662435 %\n",
        "Model processing = 2.1114839333756574 %\n",
        "Backward pass =  0.0009980201721191406\n",
        "\n",
        "Loop # 2\n",
        "Tempo de loop =  0.007141590118408203\n",
        "Forward pass =  0.005140781402587891\n",
        "Gpu copy = 80.50737408403673 %\n",
        "Model processing = 19.49262591596327 %\n",
        "Backward pass =  0.0020008087158203125\n",
        "```\n",
        "##### II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "\n",
        "Para otimizarmos o loop, o carregamento dos dados em GPU pode ser realizado pelo Dataloader fora do loop de treinamento, para tanto alterando o método __init__() da classe IMDBDataset.\n",
        "```\n",
        "def __init__(self, split, vocab):\n",
        "    #self.data = list(IMDB(split=split))[:n_samples]\n",
        "    self.data = list(balanced_dataset(IMDB(split=split), n_samples))        \n",
        "    self.vocab = vocab\n",
        "```\n",
        "##### II.2.c) Otimize o código e explique aqui.\n",
        "Substituimos então com a nova implementação, onde o dataset inteiro é pré-processado, codificado em forma One-Hot (uma vez que tensores não suportam strings) e movido para a GPU antes do processo de treinamento:\n",
        "````\n",
        "def __init__(self, split, vocab):\n",
        "    \n",
        "    # II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "    self.data = list(balanced_dataset(IMDB(split='train'), n_samples))\n",
        "\n",
        "    if preload_to_gpu:          \n",
        "        labels = [x[0] for x in self.data]\n",
        "        lines = [x[1] for x in self.data]\n",
        "\n",
        "        # One-Hot Encoding\n",
        "        self.labels_enc = []\n",
        "        for l in labels:\n",
        "        l = 1 if l == 1 else 0\n",
        "        self.labels_enc.append(l)\n",
        "        self.labels_enc = torch.tensor(self.labels_enc)\n",
        "        self.labels_enc = self.labels_enc.to(device)\n",
        "\n",
        "        self.lines_enc = []\n",
        "        for l in lines:\n",
        "        X = torch.zeros(len(vocab) + 1)\n",
        "        for word in encode_sentence(l, vocab):\n",
        "            X[word] = 1\n",
        "        self.lines_enc.append(X)\n",
        "        self.lines_enc = [tensor.to(device) for tensor in self.lines_enc]\n",
        "\n",
        "    self.vocab = vocab\n",
        "````\n",
        "##### Comparação do tempo de treinamento com a otimização (GPU RTX2060 local):\n",
        "Sem pre-load em GPU:\n",
        "````\n",
        "Epoch [1/5],             Loss: 0.6911,             Elapsed Time: 61.36 sec\n",
        "Epoch [2/5],             Loss: 0.6929,             Elapsed Time: 58.69 sec\n",
        "Epoch [3/5],             Loss: 0.6984,             Elapsed Time: 58.95 sec\n",
        "Epoch [4/5],             Loss: 0.6792,             Elapsed Time: 58.60 sec\n",
        "Epoch [5/5],             Loss: 0.6874,             Elapsed Time: 58.59 sec\n",
        "````\n",
        "Com pre-load em GPU (RTX2060)\n",
        "````\n",
        "Epoch [1/5],             Loss: 0.6896,             Elapsed Time: 3.81 sec\n",
        "Epoch [2/5],             Loss: 0.6925,             Elapsed Time: 0.58 sec\n",
        "Epoch [3/5],             Loss: 0.6933,             Elapsed Time: 0.64 sec\n",
        "Epoch [4/5],             Loss: 0.6890,             Elapsed Time: 0.58 sec\n",
        "Epoch [5/5],             Loss: 0.6904,             Elapsed Time: 0.57 sec\n",
        "````\n",
        "Notamos, no entanto, que o uso de mémória na GPU se torna muito maior, conforme pode ser visualizado abaixo (5Gb/6Gb total):\n",
        "````\n",
        "[venv:ml] $ nvidia-smi\n",
        "Mon Feb 12 08:23:42 2024\n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
        "| N/A   76C    P8    12W /  N/A |   5035MiB /  6144MiB |      1%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwvahen5D1oM"
      },
      "source": [
        "## VI - Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DtTPUBfjBj-",
        "outputId": "b5bf8ae4-5483-478e-8405-797d0bfc4571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 89.716%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.716"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "## evaluation\n",
        "def eval_mdl(model):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.round(torch.sigmoid(outputs.squeeze()))\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100* correct/total\n",
        "        print(f'Test Accuracy: {acc}%')\n",
        "    return acc\n",
        "\n",
        "eval_mdl(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWuAbn_2E1XD"
      },
      "source": [
        "##### II.3 Faça a melhor escolha do LR, analisando o valor da acurácia no conjunto de teste, utilizando para cada valor de LR, a acurácia obtida. Faça um gráfico de Acurácia vs LR e escolha o LR que forneça a maior acurácia possível."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "594pDvrHE1XD",
        "outputId": "238ac732-8c44-443e-d41c-c117c415c4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR =  0.0001\n",
            "Epoch [1/5],               Loss: 0.6921,               Elapsed Time: 0.38 sec\n",
            "Epoch [2/5],               Loss: 0.6917,               Elapsed Time: 0.38 sec\n",
            "Epoch [3/5],               Loss: 0.6907,               Elapsed Time: 0.39 sec\n",
            "Epoch [4/5],               Loss: 0.6957,               Elapsed Time: 0.38 sec\n",
            "Epoch [5/5],               Loss: 0.6980,               Elapsed Time: 0.39 sec\n",
            "Test Accuracy: 50.632%\n",
            "\n",
            "LR =  0.001\n",
            "Epoch [1/5],               Loss: 0.6934,               Elapsed Time: 0.38 sec\n",
            "Epoch [2/5],               Loss: 0.6872,               Elapsed Time: 0.38 sec\n",
            "Epoch [3/5],               Loss: 0.6907,               Elapsed Time: 0.38 sec\n",
            "Epoch [4/5],               Loss: 0.6864,               Elapsed Time: 0.40 sec\n",
            "Epoch [5/5],               Loss: 0.6854,               Elapsed Time: 0.49 sec\n",
            "Test Accuracy: 70.952%\n",
            "\n",
            "LR =  0.01\n",
            "Epoch [1/5],               Loss: 0.6776,               Elapsed Time: 0.51 sec\n",
            "Epoch [2/5],               Loss: 0.6468,               Elapsed Time: 0.74 sec\n",
            "Epoch [3/5],               Loss: 0.5534,               Elapsed Time: 0.54 sec\n",
            "Epoch [4/5],               Loss: 0.5206,               Elapsed Time: 0.60 sec\n",
            "Epoch [5/5],               Loss: 0.4706,               Elapsed Time: 0.56 sec\n",
            "Test Accuracy: 82.744%\n",
            "\n",
            "LR =  0.1\n",
            "Epoch [1/5],               Loss: 0.4087,               Elapsed Time: 0.66 sec\n",
            "Epoch [2/5],               Loss: 0.3330,               Elapsed Time: 0.70 sec\n",
            "Epoch [3/5],               Loss: 0.1901,               Elapsed Time: 0.66 sec\n",
            "Epoch [4/5],               Loss: 0.3523,               Elapsed Time: 0.65 sec\n",
            "Epoch [5/5],               Loss: 0.2368,               Elapsed Time: 0.38 sec\n",
            "Test Accuracy: 92.46%\n",
            "\n",
            "[0.0001, 0.001, 0.01, 0.1]\n",
            "[50.632, 70.952, 82.744, 92.46]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_list = [0.0001, 0.001, 0.01, 0.1]\n",
        "acc_list = []\n",
        "\n",
        "for lr in lr_list:\n",
        "    print(\"LR = \", lr)\n",
        "    model = OneHotMLP(vocab_size) # to reset weights\n",
        "    train_mdl(model, lr)\n",
        "    acc_list.append(eval_mdl(model))\n",
        "    print()\n",
        "\n",
        "print(lr_list)\n",
        "print(acc_list)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc51vZ3pE1XD"
      },
      "source": [
        "##### II.3.a) Gráfico Acurácia vs LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tx1o-KJLE1XD",
        "outputId": "9b654427-2ede-4b75-b0ba-978b657039a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.lineplot(x=lr_list, y=acc_list)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs Learning Rate\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjsz_MbpE1XD"
      },
      "source": [
        "##### II.3.b) Valor ótimo do LR\n",
        "\n",
        "Notamos que o valor ótimo para a Learning Rate foi de cerca de 0.1, com crescimento exponencial ao aumentá-la. Valores acima deste são grandes demais e não levam à otimização do modelo.\n",
        "\n",
        "##### II.3.c) Mostre a equação utilizada no gradiente descendente e qual é o papel do LR no ajuste dos parâmetros (weights) do modelo da rede neural.\n",
        "\n",
        "No processo de otimização de uma função, a fórmula utilizada para a estimativa do próximo valor da função é dada por:\n",
        "\n",
        "````\n",
        "valor atualizado = valor anterior - learning rate*gradiente\n",
        "`````\n",
        "\n",
        "Portanto o papel da LR é definir qual é o *tamanho* do passo a ser utilizado no processo de atualização."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxy2iwk0E1XD"
      },
      "source": [
        "##### II.4 Melhores a forma de tokenizar, isto é, pré-processar o dataset de modo que a codificação seja indiferente das palavras serem escritas com maiúsculas ou minúsculas e sejam pouco influenciadas pelas pontuações.\n",
        "##### II.4.a) Mostre os trechos modificados para este novo tokenizador, tanto na seção I - Vocabulário, como na seção II - Dataset.\n",
        "\n",
        "Na seção I - Vocabulário:\n",
        "\n",
        "````\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "    if (use_tokenizer):\n",
        "      tokenizer = get_tokenizer('basic_english')\n",
        "      # tokenize the sentence\n",
        "      line = tokenizer(line)\n",
        "    counter.update(line.split())\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    # Comprimento médio do texto das reviews em palavras\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    # tokenize the sentence\n",
        "    tokens = tokenizer(line)\n",
        "\n",
        "    # count the number of words\n",
        "    total_review_len += len(tokens)\n",
        "\n",
        "````\n",
        "\n",
        "Na Seção II - Dataset:\n",
        "São apenas necessárias alterações no encoder da sentença, conforme abaixo.\n",
        "\n",
        "````\n",
        "def encode_sentence(sentence, vocab, use_tokenizer):\n",
        "    if (use_tokenizer):\n",
        "       sentence = tokenizer(sentence)\n",
        "       return [vocab.get(word, 0) for word in sentence]\n",
        "    else:\n",
        "      return [vocab.get(word, 0) for word in sentence.split()] # 0 for OOV\n",
        "````\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Uxv3COE1XE"
      },
      "source": [
        "##### II.4.b) Recalcule novamente os valores do exercício I.2.c - número de tokens unknown, e apresente uma tabela comparando os novos valores com os valores obtidos com o tokenizador original e justifique os resultados obtidos.\n",
        "\n",
        "Sem o tokenizador:\n",
        "\n",
        "566141\n",
        "\n",
        "Com o tokenizador:\n",
        "\n",
        "174226\n",
        "\n",
        "Estes valores se justificam pelo fato que o tokenizador altera as palavras das sentenças, mantendo apenas radicais, de forma que menos palavras não serão encontradas na base do vocabulário.\n",
        "\n",
        "\n",
        "##### II.4.c) Execute agora no notebook inteiro com o novo tokenizador e veja o novo valor da acurácia obtido com a melhoria do tokenizador.\n",
        "\n",
        "Sem o tokenizador:\n",
        "\n",
        "Test Accuracy: 73.45% (Para LR = 0.1)\n",
        "\n",
        "Com o tokenizador\n",
        "\n",
        "Test Accuracy: 91.97% (Para LR = 0.1)\n",
        "\n",
        "O aumento da acurácia é justificado pelo fato que menos palavras de cada sentença não serão reconhecidas (OneHot encoding não terá tantos valores zerados)\n",
        "\n",
        "##### Os dados obtidos estão resumidos na tabela abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P0mX9hVE1XE",
        "outputId": "76983838-846a-4a48-ec0b-9989a07344b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uso do Tokenizador      Tokens Unknown  Test Accuracy\n",
            "--------------------  ----------------  ---------------\n",
            "Sem Tokenizador                 566141  73.45%\n",
            "Com Tokenizador                 174226  91.97%\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    ['Sem Tokenizador', 566141, '73.45%'],\n",
        "    ['Com Tokenizador', 174226, '91.97%'],\n",
        "]\n",
        "\n",
        "# Headers\n",
        "headers = ['Uso do Tokenizador', 'Tokens Unknown', 'Test Accuracy']\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(data, headers=headers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNc6iW_iE1XE"
      },
      "source": [
        "##### Seção III\n",
        "\n",
        "##### Vamos estudar agora o Data Loader da seção III do notebook. Em primeiro lugar anote a acurácia do notebook com as melhorias de eficiência de rodar em GPU, com ajustes de LR e do tokenizador. Em seguida mude o parâmetro shuffle na construção do objeto train_loader para False e execute novamente o notebook por completo e meça novamente a acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv0fHI8rE1XE",
        "outputId": "9172502f-c99d-445c-9019-c3af00763eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffle dos dados de Treinamento    Test Accuracy\n",
            "----------------------------------  ---------------\n",
            "Com Shuffle                         92.74%\n",
            "Sem Shuffle                         50.00%\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    ['Com Shuffle', '92.74%'],\n",
        "    ['Sem Shuffle', '50.00%']\n",
        "]\n",
        "\n",
        "# Headers\n",
        "headers = ['Shuffle dos dados de Treinamento', 'Test Accuracy']\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(data, headers=headers))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IA024",
      "language": "python",
      "name": "ia024"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}