{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A4HuVIYGgXg"
      },
      "source": [
        "# Notebook Processo Seletivo Aluno Especial IA-024 1S2024 FEEC-UNICAMP\n",
        "versão 5 de fevereiro de 2024, 19h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA5BWLDCKmw3",
        "outputId": "ea9dc57c-4ef3-48fc-92f3-2728bab3711f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "!pip install 'portalocker>=2.0.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "VorDvF62iyXF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.datasets import IMDB\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "dTophXo7E1W-"
      },
      "outputs": [],
      "source": [
        "# Parâmetros gerais de execução do Notebook\n",
        "# Uso do Tokenizador\n",
        "use_tokenizer = True\n",
        "\n",
        "# Preloading data\n",
        "preload_to_gpu = True\n",
        "\n",
        "# Learning Rate\n",
        "best_LR = 0.1\n",
        "\n",
        "# Shuffle Dataloader (treinamento)\n",
        "train_shuffle = True\n",
        "\n",
        "# Número de amostras usadas\n",
        "n_samples = 25000\n",
        "\n",
        "# Balanceamento do dataset\n",
        "balance_dataset = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ovJE02CwKT"
      },
      "source": [
        "## I - Vocabulário e Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqzUqy3diz0X",
        "outputId": "9ddec6ad-a438-4fc4-9c08-d69e883e711c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras positivas, negativas e totais:\n",
            "Counter({'total': 25000, 'pos': 12500, 'neg': 12500})\n",
            "\n",
            "Comprimento médio do texto em palavras\n",
            "270.68748\n",
            "\n",
            "Cinco palavras mais frequentes:\n",
            "['the', '.', ',', 'and', 'a']\n",
            "\n",
            "Cinco palavras menos frequentes:\n",
            "['voicing', 'hazard', 'lynda', 'gft', 'watergate']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# limit the vocabulary size to 20000 most frequent tokens\n",
        "vocab_size = 20000\n",
        "\n",
        "# I.1. Na célula de calcular o vocabulário, aproveite o laço sobre IMDB de treinamento e utilize um segundo contador\n",
        "# para calcular o número de amostras positivas e amostras negativas.\n",
        "# Calcule também o comprimento médio do texto em número de palavras dos textos das amostras.\n",
        "\n",
        "counter = Counter()\n",
        "counter_lbl = Counter({\"pos\": 0, \"neg\": 0, \"total\": 0})\n",
        "total_review_len = 0\n",
        "avg_review_len = 0\n",
        "\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "    if (use_tokenizer):\n",
        "      tokenizer = get_tokenizer('basic_english')\n",
        "      # tokenize the sentence\n",
        "      line = tokenizer(line)\n",
        "      counter.update(line)\n",
        "    else:\n",
        "      counter.update(line.split())\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    if (use_tokenizer):\n",
        "      total_review_len += len(line)\n",
        "    else:\n",
        "      total_review_len += len(line.split())\n",
        "\n",
        "# Comprimento médio\n",
        "avg_review_len = total_review_len / counter_lbl['total']\n",
        "\n",
        "# I.2 Mostre as cinco palavras mais frequentes do vocabulário e as cinco palavras menos frequentes.\n",
        "# Qual é o código do token que está sendo utilizado quando a palavra não está no vocabulário?\n",
        "# Calcule quantos tokens das frases do conjunto de treinamento que não estão no vocabulário.\n",
        "\n",
        "# create a vocabulary of the 20000 most frequent tokens\n",
        "most_frequent_words = sorted(counter, key=counter.get, reverse=True)[:vocab_size]\n",
        "vocab = {word: i for i, word in enumerate(most_frequent_words, 1)} # words indexed from 1 to 20000\n",
        "vocab_size = len(vocab) #Errata\n",
        "\n",
        "print(\"Amostras positivas, negativas e totais:\")\n",
        "print(counter_lbl)\n",
        "print()\n",
        "\n",
        "print(\"Comprimento médio do texto em palavras\")\n",
        "print(avg_review_len)\n",
        "print()\n",
        "\n",
        "print(\"Cinco palavras mais frequentes:\")\n",
        "print(most_frequent_words[:5])\n",
        "print()\n",
        "\n",
        "print(\"Cinco palavras menos frequentes:\")\n",
        "print(most_frequent_words[-5:])\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rZn-m1Mi110",
        "outputId": "13d102e4-fd46-4a45-e5aa-bee521a45b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de tokens que não estão no vocabulário na base de treinamento:\n",
            "174226\n"
          ]
        }
      ],
      "source": [
        "# I.2 Calcule quantos tokens das frases do conjunto de treinamento que não estão no vocabulário.\n",
        "\n",
        "def encode_sentence(sentence, vocab, use_tokenizer):\n",
        "    if (use_tokenizer):\n",
        "       sentence = tokenizer(sentence)\n",
        "       return [vocab.get(word, 0) for word in sentence]\n",
        "    else:\n",
        "      return [vocab.get(word, 0) for word in sentence.split()] # 0 for OOV\n",
        "\n",
        "encode_sentence(\"I like Pizza\", vocab, use_tokenizer)\n",
        "\n",
        "# Cálculo do número de tokens que não estão no vocabulário na base de treinamento:\n",
        "tokens = []\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "  tokens.extend(encode_sentence(line, vocab, use_tokenizer))\n",
        "\n",
        "print(\"Número de tokens que não estão no vocabulário na base de treinamento:\")\n",
        "print(tokens.count(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7tJ5XHQS7g6"
      },
      "source": [
        "#### I.2 Qual é o código do token que está sendo utilizado quando a palavra não está no vocabulário?\n",
        "\n",
        "Na função de dicionário dict.get() o segundo parâmetro indica o valor default caso a palavra não seja encontrada no dicionário. Nesse caso o código do token usado é o número zero.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri9lyeL_zx-1"
      },
      "source": [
        "#### I.3.a) Qual é a razão pela qual o modelo preditivo conseguiu acertar 100% das amostras de teste do dataset selecionado com apenas as primeiras 200 amostras?\n",
        "\n",
        "Ao reduzirmos a base de treinamento para apenas 200 amostras, a base se tornou totalmente desbalanceada. Como pudemos verificar, temos 200 amostras classificadas como negativas e nenhuma como positiva.\n",
        "Portanto a taxa de acurácia calculada sobre a classificação da base de testes depende unicamente da percentagem de amostras positivas ou negativas nesta base.\n",
        "\n",
        "#### I.3.b) Modifique a forma de selecionar 200 amostras do dataset, porém garantindo que ele continue balanceado, isto é, aproximadamente 100 amostras positivas e 100 amostras negativas.\n",
        "\n",
        "Para obtermos um dataset balanceado, usaremos uma função que seleciona amostras do dataset de acordo com a classificação e cria um dataset com a quantidade de amostras de cada classificação desejada conforme abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwYM7hAGBCeQ",
        "outputId": "5ce3cbfe-fe21-4f3e-cf05-3f526ec36da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comprimento médio do texto em palavras na base balanceada\n",
            "270.68748\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Função para selecionar dados balanceados\n",
        "from random import shuffle\n",
        "\n",
        "def balanced_dataset(data, size):\n",
        "  if (balance_dataset):\n",
        "    data_pos = [(label,line) for label, line in data if label == 2][:int(size/2)]\n",
        "    data_neg = [(label,line) for label, line in data if label == 1][:int(size/2)]\n",
        "\n",
        "    data_bal = data_pos + data_neg\n",
        "    shuffle(data_bal)\n",
        "\n",
        "    return data_bal\n",
        "  else:\n",
        "     return data\n",
        "\n",
        "# Aplicando sobre a base de treinamento\n",
        "\n",
        "train_data = IMDB(split='train')\n",
        "counter = Counter()\n",
        "total_review_len = 0\n",
        "avg_review_len = 0\n",
        "\n",
        "for (label, line) in list(balanced_dataset(train_data, n_samples)):\n",
        "    counter.update(line.split())\n",
        "\n",
        "    # Comprimento médio do texto das reviews em palavras\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    # tokenize the sentence\n",
        "    tokens = tokenizer(line)\n",
        "\n",
        "    # count the number of words\n",
        "    total_review_len += len(tokens)\n",
        "\n",
        "# Comprimento médio\n",
        "avg_review_len = total_review_len / n_samples\n",
        "\n",
        "print(\"Comprimento médio do texto em palavras na base balanceada\")\n",
        "print(avg_review_len)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iV4bF8cDAj1"
      },
      "source": [
        "## II - Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "VDUyZoTPi262"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import one_hot\n",
        "# Dataset Class with One-hot Encoding\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, split, vocab):\n",
        "\n",
        "        # II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "        self.data = list(balanced_dataset(IMDB(split='train'), n_samples))\n",
        "\n",
        "        if preload_to_gpu:\n",
        "          labels = [x[0] for x in self.data]\n",
        "          lines = [x[1] for x in self.data]\n",
        "\n",
        "          # One-Hot Encoding\n",
        "          self.labels_enc = []\n",
        "          for l in labels:\n",
        "            l = 1 if l == 1 else 0\n",
        "            self.labels_enc.append(l)\n",
        "          self.labels_enc = torch.tensor(self.labels_enc)\n",
        "          self.labels_enc = self.labels_enc.to(device)\n",
        "\n",
        "          self.lines_enc = []\n",
        "          for l in lines:\n",
        "            X = torch.zeros(len(vocab) + 1)\n",
        "\n",
        "            for word in encode_sentence(l, vocab, use_tokenizer):\n",
        "              X[word] = 1\n",
        "            self.lines_enc.append(X)\n",
        "          self.lines_enc = [tensor.to(device) for tensor in self.lines_enc]\n",
        "\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not preload_to_gpu:\n",
        "          label, line = self.data[idx]\n",
        "          label = 1 if label == 1 else 0\n",
        "\n",
        "          # one-hot encoding\n",
        "          X = torch.zeros(len(self.vocab) + 1)\n",
        "\n",
        "          for word in encode_sentence(line, self.vocab, use_tokenizer):\n",
        "              X[word] = 1\n",
        "\n",
        "          return X, torch.tensor(label)\n",
        "        else:\n",
        "          return self.lines_enc[idx], self.labels_enc[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "pqXuAWR0E1XA",
        "outputId": "d7d4047f-0750-4222-ff10-f1fd0924f51d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras positivas, negativas e totais:\n",
            "Counter({'total': 25000, 'pos': 12500, 'neg': 12500})\n",
            "\n",
            "Quantidade média de palavras codificadas em cada vetor one-hot\n",
            "139.59268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load Data with One-hot Encoding\n",
        "train_data = IMDBDataset('train', vocab)\n",
        "test_data = IMDBDataset('test', vocab)\n",
        "\n",
        "# II.1.a) Investigue o dataset criado na linha 24. Faça um código que aplique um laço sobre o dataset train_data\n",
        "# e calcule novamente quantas amostras positivas e negativas do dataset.\n",
        "# II.1.b) Calcule também o número médio de palavras codificadas em cada vetor one-hot.\n",
        "# Compare este valor com o comprimento médio de cada texto (contado em palavras), conforme calculado no exercício\n",
        "\n",
        "counter_lbl = Counter({\"pos\": 0, \"neg\": 0, \"total\": 0})\n",
        "words_encoded = 0\n",
        "for (oneHot, sentiment) in train_data:\n",
        "\n",
        "    words = oneHot.tolist()\n",
        "    label = sentiment.item()\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    hot_encoded = sum(words[i] for i in range(len(words)) if words[i] != 0)\n",
        "    words_encoded +=  hot_encoded\n",
        "\n",
        "avg_words_enc = words_encoded / counter_lbl['total']\n",
        "\n",
        "print(\"Amostras positivas, negativas e totais:\")\n",
        "print(counter_lbl)\n",
        "print()\n",
        "\n",
        "print(\"Quantidade média de palavras codificadas em cada vetor one-hot\")\n",
        "print(avg_words_enc)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdM6ojduRqrw"
      },
      "source": [
        "#### II.1.b Compare este valor com o comprimento médio de cada texto (contado em palavras), conforme calculado no exercício I.1.c. e explique a diferença.\n",
        "\n",
        "No exercício I.1.c, o comprimento médio do texto em palavras depois de passar pelo tokenizador foi de cerca de 270 palavras. Essa diferença do vetor One-Hot se deve ao fato que o vetor one-hot só codifica as palavras que foram identificadas no dicionário, enquanto que o comprimento médio considera todas as palavras das sentenças. Ou seja, palavras que não foram codificadas no dicionário serão representadas por zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7RMPSvMDL5U"
      },
      "source": [
        "## III - Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Y7tcZv2YDIog"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "# define dataloaders\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=train_shuffle)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwPeJ7h8DahT"
      },
      "source": [
        "## IV - Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "6QuDhWvji7lt"
      },
      "outputs": [],
      "source": [
        "class OneHotMLP(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(OneHotMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(vocab_size+1, 200)\n",
        "        self.fc2 = nn.Linear(200, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        o = self.fc1(x.float())\n",
        "        o = self.relu(o)\n",
        "        return self.fc2(o)\n",
        "\n",
        "# Model instantiation\n",
        "model = OneHotMLP(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVAhdFGXDepU"
      },
      "source": [
        "## V - Laço de Treinamento - Otimização da função de Perda pelo Gradiente descendente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaH1Uv3yHih5",
        "outputId": "70834897-42a0-49da-af98-559ec779f200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "else:\n",
        "    print('using CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh_pe8rni93_",
        "outputId": "f33c6871-2ead-4d34-a410-ddcd93370c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5],               Loss: 0.4015,               Elapsed Time: 0.62 sec\n",
            "Epoch [2/5],               Loss: 0.3670,               Elapsed Time: 0.49 sec\n",
            "Epoch [3/5],               Loss: 0.2635,               Elapsed Time: 0.50 sec\n",
            "Epoch [4/5],               Loss: 0.2753,               Elapsed Time: 0.52 sec\n",
            "Epoch [5/5],               Loss: 0.3098,               Elapsed Time: 0.39 sec\n"
          ]
        }
      ],
      "source": [
        "# II.2 Com a o notebook configurado para GPU T4, meça o tempo de dois laços dentro do\n",
        "# for da linha 13 (coloque um break após dois laços) e determine quanto demora\n",
        "# demora para o passo de forward (linhas 14 a 18), para o backward (linhas 20, 21 e 22)\n",
        "# e o tempo total de um laço. Faça as contas e identifique o trecho que é mais demorado.\n",
        "# II.2.a) Tempo do laço = ; Tempo do forward = ;Tempo do backward = ; Conclusão.\n",
        "\n",
        "import time\n",
        "\n",
        "# Transformando em função o treinamento\n",
        "def train_mdl(model, lr):\n",
        "  # Debug\n",
        "  print_loop = False\n",
        "\n",
        "  model = model.to(device)\n",
        "  # Define loss and optimizer\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 5\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      start_time = time.time()  # Start time of the epoch\n",
        "      model.train()\n",
        "\n",
        "      loop_count = 0\n",
        "\n",
        "      for inputs, labels in train_loader:\n",
        "          loop_start = time.time()\n",
        "          if(loop_count == 2 and print_loop):\n",
        "            # Para medição do tempo do loop.\n",
        "            break\n",
        "\n",
        "          forward_start = time.time()\n",
        "\n",
        "          if not preload_to_gpu:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "          gpu_cpy_time = time.time() - forward_start\n",
        "          # Forward pass\n",
        "          model_start = time.time()\n",
        "          outputs = model(inputs)\n",
        "          model_time = time.time() - model_start\n",
        "          loss = criterion(outputs.squeeze(), labels.float())\n",
        "          forward_time = time.time() - forward_start\n",
        "\n",
        "          # Backward and optimize\n",
        "          backward_start = time.time()\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          backward_time = time.time() - backward_start\n",
        "\n",
        "          # Loop optimization\n",
        "          loop_count += 1\n",
        "          loop_time = time.time() - loop_start\n",
        "          if (epoch == 0 and print_loop):\n",
        "            print(\"Loop #\", loop_count)\n",
        "            print(\"Tempo de loop = \", loop_time)\n",
        "            print(\"Forward pass = \", forward_time)\n",
        "            gpu_percent = gpu_cpy_time/forward_time\n",
        "            print(\"Gpu copy = \" + str(gpu_percent*100) + \" %\")\n",
        "            print(\"Model processing = \" + str((1 - gpu_percent)*100) + \" %\")\n",
        "            print(\"Backward pass = \", backward_time)\n",
        "            print()\n",
        "\n",
        "      end_time = time.time()  # End time of the epoch\n",
        "      epoch_duration = end_time - start_time  # Duration of epoch\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
        "              Loss: {loss.item():.4f}, \\\n",
        "              Elapsed Time: {epoch_duration:.2f} sec')\n",
        "\n",
        "# Primeiro treinamento com a melhor taxa de Learning Rate\n",
        "model = OneHotMLP(vocab_size)\n",
        "train_mdl(model, best_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBswOILbX39h"
      },
      "source": [
        "##### II.2.a) Medição dos tempos de loop\n",
        "\n",
        "Notamos que o tempo do passo do forward leva mais tempo que o passo de backward, conforme os dados obtidos abaixo para a primeira época do treinamento.\n",
        "Também notamos que a maior parte to tempo do loop de forward é gasto com a transferência dos dados da CPU para a GPU (97% no primeiro loop).\n",
        "\n",
        "**Para 200 amostras**:\n",
        "\n",
        "```\n",
        "Loop # 1\n",
        "Tempo de loop =  0.048320770263671875\n",
        "Forward pass =  0.047322750091552734\n",
        "Gpu copy = 97.88851606662435 %\n",
        "Model processing = 2.1114839333756574 %\n",
        "Backward pass =  0.0009980201721191406\n",
        "\n",
        "Loop # 2\n",
        "Tempo de loop =  0.007141590118408203\n",
        "Forward pass =  0.005140781402587891\n",
        "Gpu copy = 80.50737408403673 %\n",
        "Model processing = 19.49262591596327 %\n",
        "Backward pass =  0.0020008087158203125\n",
        "```\n",
        "##### II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "\n",
        "Para otimizarmos o loop, o carregamento dos dados em GPU pode ser realizado pelo Dataloader fora do loop de treinamento, para tanto alterando o método __init__() da classe IMDBDataset.\n",
        "```\n",
        "def __init__(self, split, vocab):\n",
        "    #self.data = list(IMDB(split=split))[:n_samples]\n",
        "    self.data = list(balanced_dataset(IMDB(split=split), n_samples))        \n",
        "    self.vocab = vocab\n",
        "```\n",
        "##### II.2.c) Otimize o código e explique aqui.\n",
        "Substituimos então com a nova implementação, onde o dataset inteiro é pré-processado, codificado em forma One-Hot (uma vez que tensores não suportam strings) e movido para a GPU antes do processo de treinamento:\n",
        "````\n",
        "def __init__(self, split, vocab):\n",
        "    \n",
        "    # II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "    self.data = list(balanced_dataset(IMDB(split='train'), n_samples))\n",
        "\n",
        "    if preload_to_gpu:          \n",
        "        labels = [x[0] for x in self.data]\n",
        "        lines = [x[1] for x in self.data]\n",
        "\n",
        "        # One-Hot Encoding\n",
        "        self.labels_enc = []\n",
        "        for l in labels:\n",
        "        l = 1 if l == 1 else 0\n",
        "        self.labels_enc.append(l)\n",
        "        self.labels_enc = torch.tensor(self.labels_enc)\n",
        "        self.labels_enc = self.labels_enc.to(device)\n",
        "\n",
        "        self.lines_enc = []\n",
        "        for l in lines:\n",
        "        X = torch.zeros(len(vocab) + 1)\n",
        "        for word in encode_sentence(l, vocab):\n",
        "            X[word] = 1\n",
        "        self.lines_enc.append(X)\n",
        "        self.lines_enc = [tensor.to(device) for tensor in self.lines_enc]\n",
        "\n",
        "    self.vocab = vocab\n",
        "````\n",
        "##### Comparação do tempo de treinamento com a otimização (GPU RTX2060 local):\n",
        "Sem pre-load em GPU:\n",
        "````\n",
        "Epoch [1/5],             Loss: 0.6911,             Elapsed Time: 61.36 sec\n",
        "Epoch [2/5],             Loss: 0.6929,             Elapsed Time: 58.69 sec\n",
        "Epoch [3/5],             Loss: 0.6984,             Elapsed Time: 58.95 sec\n",
        "Epoch [4/5],             Loss: 0.6792,             Elapsed Time: 58.60 sec\n",
        "Epoch [5/5],             Loss: 0.6874,             Elapsed Time: 58.59 sec\n",
        "````\n",
        "Com pre-load em GPU (RTX2060)\n",
        "````\n",
        "Epoch [1/5],             Loss: 0.6896,             Elapsed Time: 3.81 sec\n",
        "Epoch [2/5],             Loss: 0.6925,             Elapsed Time: 0.58 sec\n",
        "Epoch [3/5],             Loss: 0.6933,             Elapsed Time: 0.64 sec\n",
        "Epoch [4/5],             Loss: 0.6890,             Elapsed Time: 0.58 sec\n",
        "Epoch [5/5],             Loss: 0.6904,             Elapsed Time: 0.57 sec\n",
        "````\n",
        "Notamos, no entanto, que o uso de mémória na GPU se torna muito maior, conforme pode ser visualizado abaixo (5Gb/6Gb total):\n",
        "````\n",
        "[venv:ml] $ nvidia-smi\n",
        "Mon Feb 12 08:23:42 2024\n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
        "| N/A   76C    P8    12W /  N/A |   5035MiB /  6144MiB |      1%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwvahen5D1oM"
      },
      "source": [
        "## VI - Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DtTPUBfjBj-",
        "outputId": "c83df1a3-d408-4330-dbfe-e6eb8dece4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 91.808%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.808"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "## evaluation\n",
        "def eval_mdl(model):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.round(torch.sigmoid(outputs.squeeze()))\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100* correct/total\n",
        "        print(f'Test Accuracy: {acc}%')\n",
        "    return acc\n",
        "\n",
        "eval_mdl(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWuAbn_2E1XD"
      },
      "source": [
        "##### II.3 Faça a melhor escolha do LR, analisando o valor da acurácia no conjunto de teste, utilizando para cada valor de LR, a acurácia obtida. Faça um gráfico de Acurácia vs LR e escolha o LR que forneça a maior acurácia possível."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "594pDvrHE1XD",
        "outputId": "d950e637-748e-40d9-e3aa-fd399d0659d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR =  0.0001\n",
            "Epoch [1/5],               Loss: 0.6901,               Elapsed Time: 0.39 sec\n",
            "Epoch [2/5],               Loss: 0.7004,               Elapsed Time: 0.39 sec\n",
            "Epoch [3/5],               Loss: 0.6899,               Elapsed Time: 0.39 sec\n",
            "Epoch [4/5],               Loss: 0.6988,               Elapsed Time: 0.38 sec\n",
            "Epoch [5/5],               Loss: 0.6826,               Elapsed Time: 0.39 sec\n",
            "Test Accuracy: 50.0%\n",
            "\n",
            "LR =  0.001\n",
            "Epoch [1/5],               Loss: 0.6899,               Elapsed Time: 0.38 sec\n",
            "Epoch [2/5],               Loss: 0.6879,               Elapsed Time: 0.39 sec\n",
            "Epoch [3/5],               Loss: 0.6854,               Elapsed Time: 0.38 sec\n",
            "Epoch [4/5],               Loss: 0.6893,               Elapsed Time: 0.41 sec\n",
            "Epoch [5/5],               Loss: 0.6839,               Elapsed Time: 0.39 sec\n",
            "Test Accuracy: 70.572%\n",
            "\n",
            "LR =  0.01\n",
            "Epoch [1/5],               Loss: 0.6680,               Elapsed Time: 0.40 sec\n",
            "Epoch [2/5],               Loss: 0.6309,               Elapsed Time: 0.39 sec\n",
            "Epoch [3/5],               Loss: 0.5382,               Elapsed Time: 0.38 sec\n",
            "Epoch [4/5],               Loss: 0.5353,               Elapsed Time: 0.39 sec\n",
            "Epoch [5/5],               Loss: 0.4217,               Elapsed Time: 0.39 sec\n",
            "Test Accuracy: 82.5%\n",
            "\n",
            "LR =  0.1\n",
            "Epoch [1/5],               Loss: 0.4130,               Elapsed Time: 0.40 sec\n",
            "Epoch [2/5],               Loss: 0.3986,               Elapsed Time: 0.39 sec\n",
            "Epoch [3/5],               Loss: 0.2052,               Elapsed Time: 0.40 sec\n",
            "Epoch [4/5],               Loss: 0.1687,               Elapsed Time: 0.39 sec\n",
            "Epoch [5/5],               Loss: 0.1134,               Elapsed Time: 0.38 sec\n",
            "Test Accuracy: 92.436%\n",
            "\n",
            "[0.0001, 0.001, 0.01, 0.1]\n",
            "[50.0, 70.572, 82.5, 92.436]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_list = [0.0001, 0.001, 0.01, 0.1]\n",
        "acc_list = []\n",
        "\n",
        "for lr in lr_list:\n",
        "    print(\"LR = \", lr)\n",
        "    model = OneHotMLP(vocab_size) # to reset weights\n",
        "    train_mdl(model, lr)\n",
        "    acc_list.append(eval_mdl(model))\n",
        "    print()\n",
        "\n",
        "print(lr_list)\n",
        "print(acc_list)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc51vZ3pE1XD"
      },
      "source": [
        "##### II.3.a) Gráfico Acurácia vs LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "tx1o-KJLE1XD",
        "outputId": "def6b016-1bd8-46dc-91c6-55fcc699da7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.lineplot(x=lr_list, y=acc_list)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs Learning Rate\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjsz_MbpE1XD"
      },
      "source": [
        "##### II.3.b) Valor ótimo do LR\n",
        "\n",
        "Notamos que o valor ótimo para a Learning Rate foi de cerca de 0.1, com crescimento exponencial ao aumentá-la. Valores acima deste são grandes demais e não levam à otimização do modelo.\n",
        "\n",
        "##### II.3.c) Mostre a equação utilizada no gradiente descendente e qual é o papel do LR no ajuste dos parâmetros (weights) do modelo da rede neural.\n",
        "\n",
        "No processo de otimização de uma função, a fórmula utilizada para a estimativa do próximo valor da função é dada por:\n",
        "\n",
        "````\n",
        "valor atualizado = valor anterior - learning rate*gradiente\n",
        "`````\n",
        "\n",
        "Portanto o papel da LR é definir qual é o *tamanho* do passo a ser utilizado no processo de atualização."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxy2iwk0E1XD"
      },
      "source": [
        "##### II.4 Melhores a forma de tokenizar, isto é, pré-processar o dataset de modo que a codificação seja indiferente das palavras serem escritas com maiúsculas ou minúsculas e sejam pouco influenciadas pelas pontuações.\n",
        "##### II.4.a) Mostre os trechos modificados para este novo tokenizador, tanto na seção I - Vocabulário, como na seção II - Dataset.\n",
        "\n",
        "Na seção I - Vocabulário:\n",
        "\n",
        "````\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "    if (use_tokenizer):\n",
        "      tokenizer = get_tokenizer('basic_english')\n",
        "      # tokenize the sentence\n",
        "      line = tokenizer(line)\n",
        "    counter.update(line.split())\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    # Comprimento médio do texto das reviews em palavras\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    # tokenize the sentence\n",
        "    tokens = tokenizer(line)\n",
        "\n",
        "    # count the number of words\n",
        "    total_review_len += len(tokens)\n",
        "\n",
        "````\n",
        "\n",
        "Na Seção II - Dataset:\n",
        "São apenas necessárias alterações no encoder da sentença, conforme abaixo.\n",
        "\n",
        "````\n",
        "def encode_sentence(sentence, vocab, use_tokenizer):\n",
        "    if (use_tokenizer):\n",
        "       sentence = tokenizer(sentence)\n",
        "       return [vocab.get(word, 0) for word in sentence]\n",
        "    else:\n",
        "      return [vocab.get(word, 0) for word in sentence.split()] # 0 for OOV\n",
        "````\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Uxv3COE1XE"
      },
      "source": [
        "##### II.4.b) Recalcule novamente os valores do exercício I.2.c - número de tokens unknown, e apresente uma tabela comparando os novos valores com os valores obtidos com o tokenizador original e justifique os resultados obtidos.\n",
        "\n",
        "Sem o tokenizador:\n",
        "\n",
        "566141\n",
        "\n",
        "Com o tokenizador:\n",
        "\n",
        "174226\n",
        "\n",
        "Estes valores se justificam pelo fato que o tokenizador altera as palavras das sentenças, mantendo apenas radicais, de forma que menos palavras não serão encontradas na base do vocabulário.\n",
        "\n",
        "\n",
        "##### II.4.c) Execute agora no notebook inteiro com o novo tokenizador e veja o novo valor da acurácia obtido com a melhoria do tokenizador.\n",
        "\n",
        "Sem o tokenizador:\n",
        "\n",
        "Test Accuracy: 73.45% (Para LR = 0.1)\n",
        "\n",
        "Com o tokenizador\n",
        "\n",
        "Test Accuracy: 91.97% (Para LR = 0.1)\n",
        "\n",
        "O aumento da acurácia é justificado pelo fato que menos palavras de cada sentença não serão reconhecidas (OneHot encoding não terá tantos valores zerados)\n",
        "\n",
        "##### Os dados obtidos estão resumidos na tabela abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "0P0mX9hVE1XE",
        "outputId": "76ce4f2b-85e5-446e-e1d8-0be3c5f81107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uso do Tokenizador      Tokens Unknown  Test Accuracy\n",
            "--------------------  ----------------  ---------------\n",
            "Sem Tokenizador                 566141  73.45%\n",
            "Com Tokenizador                 174226  91.97%\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    ['Sem Tokenizador', 566141, '73.45%'],\n",
        "    ['Com Tokenizador', 174226, '91.97%'],\n",
        "]\n",
        "\n",
        "# Headers\n",
        "headers = ['Uso do Tokenizador', 'Tokens Unknown', 'Test Accuracy']\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(data, headers=headers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNc6iW_iE1XE"
      },
      "source": [
        "##### Seção III\n",
        "\n",
        "##### Vamos estudar agora o Data Loader da seção III do notebook. Em primeiro lugar anote a acurácia do notebook com as melhorias de eficiência de rodar em GPU, com ajustes de LR e do tokenizador. Em seguida mude o parâmetro shuffle na construção do objeto train_loader para False e execute novamente o notebook por completo e meça novamente a acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "dv0fHI8rE1XE",
        "outputId": "167a85d2-44d6-41dc-af4b-55d0241aad08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffle dos dados de Treinamento    Test Accuracy\n",
            "----------------------------------  ---------------\n",
            "Com Shuffle                         92.74%\n",
            "Sem Shuffle                         x\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    ['Com Shuffle', '92.74%'],\n",
        "    ['Sem Shuffle', 'x']\n",
        "]\n",
        "\n",
        "# Headers\n",
        "headers = ['Shuffle dos dados de Treinamento', 'Test Accuracy']\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(data, headers=headers))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IA024",
      "language": "python",
      "name": "ia024"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}