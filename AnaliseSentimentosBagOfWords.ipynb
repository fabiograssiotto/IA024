{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A4HuVIYGgXg"
      },
      "source": [
        "# Notebook Processo Seletivo Aluno Especial IA-024 1S2024 FEEC-UNICAMP\n",
        "versão 5 de fevereiro de 2024, 19h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA5BWLDCKmw3",
        "outputId": "d393f695-7da4-46d6-8d34-9b44c12e9e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (0.17.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.2.0 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torchtext) (2.2.0+cu118)\n",
            "Requirement already satisfied: numpy in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torchtext) (1.26.3)\n",
            "Requirement already satisfied: torchdata==0.7.1 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torch==2.2.0->torchtext) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torch==2.2.0->torchtext) (4.8.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torch==2.2.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torch==2.2.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torch==2.2.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torch==2.2.0->torchtext) (2023.4.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from torchdata==0.7.1->torchtext) (1.26.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from requests->torchtext) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from jinja2->torch==2.2.0->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\fabio.grassiotto\\research\\venv\\ml\\lib\\site-packages (from sympy->torch==2.2.0->torchtext) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: \"'portalocker\"\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "!pip install 'portalocker>=2.0.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VorDvF62iyXF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.datasets import IMDB\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parâmetros gerais de execução do Notebook\n",
        "# Uso do Tokenizador\n",
        "use_tokenizer = True\n",
        "\n",
        "# Preloading data\n",
        "preload_to_gpu = True\n",
        "\n",
        "# Learning Rate\n",
        "best_LR = 0.5\n",
        "\n",
        "# Shuffle Dataloader (treinamento)\n",
        "train_shuffle = True\n",
        "\n",
        "# Número de amostras usadas\n",
        "n_samples = 25000 \n",
        "\n",
        "# Balanceamento do dataset \n",
        "balance_dataset = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ovJE02CwKT"
      },
      "source": [
        "## I - Vocabulário e Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqzUqy3diz0X",
        "outputId": "16424773-5f91-40a2-847d-36a3a8eb6a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amostras positivas, negativas e totais:\n",
            "Counter({'total': 25000, 'pos': 12500, 'neg': 12500})\n",
            "\n",
            "Comprimento médio do texto em palavras\n",
            "270.68748\n",
            "\n",
            "Cinco palavras mais frequentes:\n",
            "['the', '.', ',', 'and', 'a']\n",
            "\n",
            "Cinco palavras menos frequentes:\n",
            "['voicing', 'hazard', 'lynda', 'gft', 'watergate']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# limit the vocabulary size to 20000 most frequent tokens\n",
        "vocab_size = 20000\n",
        "\n",
        "# I.1. Na célula de calcular o vocabulário, aproveite o laço sobre IMDB de treinamento e utilize um segundo contador\n",
        "# para calcular o número de amostras positivas e amostras negativas.\n",
        "# Calcule também o comprimento médio do texto em número de palavras dos textos das amostras.\n",
        "\n",
        "counter = Counter()\n",
        "counter_lbl = Counter({\"pos\": 0, \"neg\": 0, \"total\": 0})\n",
        "total_review_len = 0\n",
        "avg_review_len = 0\n",
        "\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "    if (use_tokenizer):\n",
        "      tokenizer = get_tokenizer('basic_english')\n",
        "      # tokenize the sentence\n",
        "      line = tokenizer(line)\n",
        "      counter.update(line)\n",
        "    else:\n",
        "      counter.update(line.split())\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    if (use_tokenizer):\n",
        "      total_review_len += len(line)\n",
        "    else:\n",
        "      total_review_len += len(line.split())\n",
        "\n",
        "# Comprimento médio\n",
        "avg_review_len = total_review_len / counter_lbl['total']\n",
        "\n",
        "# I.2 Mostre as cinco palavras mais frequentes do vocabulário e as cinco palavras menos frequentes.\n",
        "# Qual é o código do token que está sendo utilizado quando a palavra não está no vocabulário?\n",
        "# Calcule quantos tokens das frases do conjunto de treinamento que não estão no vocabulário.\n",
        "\n",
        "# create a vocabulary of the 20000 most frequent tokens\n",
        "most_frequent_words = sorted(counter, key=counter.get, reverse=True)[:vocab_size]\n",
        "vocab = {word: i for i, word in enumerate(most_frequent_words, 1)} # words indexed from 1 to 20000\n",
        "vocab_size = len(vocab) #Errata\n",
        "\n",
        "print(\"Amostras positivas, negativas e totais:\")\n",
        "print(counter_lbl)\n",
        "print()\n",
        "\n",
        "print(\"Comprimento médio do texto em palavras\")\n",
        "print(avg_review_len)\n",
        "print()\n",
        "\n",
        "print(\"Cinco palavras mais frequentes:\")\n",
        "print(most_frequent_words[:5])\n",
        "print()\n",
        "\n",
        "print(\"Cinco palavras menos frequentes:\")\n",
        "print(most_frequent_words[-5:])\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rZn-m1Mi110",
        "outputId": "6968e8cd-b054-4489-dfd6-2fa2384d2e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de tokens que não estão no vocabulário na base de treinamento:\n",
            "174226\n"
          ]
        }
      ],
      "source": [
        "# I.2 Calcule quantos tokens das frases do conjunto de treinamento que não estão no vocabulário.\n",
        "\n",
        "def encode_sentence(sentence, vocab, use_tokenizer):\n",
        "    if (use_tokenizer):\n",
        "       sentence = tokenizer(sentence)\n",
        "       return [vocab.get(word, 0) for word in sentence]\n",
        "    else:\n",
        "      return [vocab.get(word, 0) for word in sentence.split()] # 0 for OOV\n",
        "\n",
        "encode_sentence(\"I like Pizza\", vocab, use_tokenizer)\n",
        "\n",
        "# Cálculo do número de tokens que não estão no vocabulário na base de treinamento:\n",
        "tokens = []\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "  tokens.extend(encode_sentence(line, vocab, use_tokenizer))\n",
        "\n",
        "print(\"Número de tokens que não estão no vocabulário na base de treinamento:\")\n",
        "print(tokens.count(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7tJ5XHQS7g6"
      },
      "source": [
        "#### I.2 Qual é o código do token que está sendo utilizado quando a palavra não está no vocabulário?\n",
        "\n",
        "Na função de dicionário dict.get() o segundo parâmetro indica o valor default caso a palavra não seja encontrada no dicionário. Nesse caso o código do token usado é o número zero.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri9lyeL_zx-1"
      },
      "source": [
        "#### I.3.a) Qual é a razão pela qual o modelo preditivo conseguiu acertar 100% das amostras de teste do dataset selecionado com apenas as primeiras 200 amostras?\n",
        "\n",
        "Ao reduzirmos a base de treinamento para apenas 200 amostras, a base se tornou totalmente desbalanceada. Como pudemos verificar, temos 200 amostras classificadas como negativas e nenhuma como positiva.\n",
        "Portanto a taxa de acurácia calculada sobre a classificação da base de testes depende unicamente da percentagem de amostras positivas ou negativas nesta base.\n",
        "\n",
        "#### I.3.b) Modifique a forma de selecionar 200 amostras do dataset, porém garantindo que ele continue balanceado, isto é, aproximadamente 100 amostras positivas e 100 amostras negativas.\n",
        "\n",
        "Para obtermos um dataset balanceado, usaremos uma função que seleciona amostras do dataset de acordo com a classificação e cria um dataset com a quantidade de amostras de cada classificação desejada conforme abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwYM7hAGBCeQ",
        "outputId": "fd5eb4cb-fd80-4f97-8dbc-6494fbc6c16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comprimento médio do texto em palavras na base balanceada\n",
            "270.68748\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Função para selecionar dados balanceados\n",
        "from random import shuffle\n",
        "\n",
        "def balanced_dataset(data, size):\n",
        "  if (balance_dataset):\n",
        "    data_pos = [(label,line) for label, line in data if label == 2][:int(size/2)]\n",
        "    data_neg = [(label,line) for label, line in data if label == 1][:int(size/2)]\n",
        "\n",
        "    data_bal = data_pos + data_neg\n",
        "    shuffle(data_bal)\n",
        "\n",
        "    return data_bal\n",
        "  else:\n",
        "     return data\n",
        "\n",
        "# Aplicando sobre a base de treinamento\n",
        "\n",
        "train_data = IMDB(split='train')\n",
        "counter = Counter()\n",
        "total_review_len = 0\n",
        "avg_review_len = 0\n",
        "\n",
        "for (label, line) in list(balanced_dataset(train_data, n_samples)):\n",
        "    counter.update(line.split())\n",
        "\n",
        "    # Comprimento médio do texto das reviews em palavras\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    # tokenize the sentence\n",
        "    tokens = tokenizer(line)\n",
        "\n",
        "    # count the number of words\n",
        "    total_review_len += len(tokens)\n",
        "\n",
        "# Comprimento médio\n",
        "avg_review_len = total_review_len / n_samples\n",
        "\n",
        "print(\"Comprimento médio do texto em palavras na base balanceada\")\n",
        "print(avg_review_len)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iV4bF8cDAj1"
      },
      "source": [
        "## II - Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDUyZoTPi262",
        "outputId": "359eee71-f441-4b39-c93e-b2cb89d68881"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import one_hot\n",
        "# Dataset Class with One-hot Encoding\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, split, vocab):\n",
        "        \n",
        "        # II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "        self.data = list(balanced_dataset(IMDB(split='train'), n_samples))\n",
        "\n",
        "        if preload_to_gpu:          \n",
        "          labels = [x[0] for x in self.data]\n",
        "          lines = [x[1] for x in self.data]\n",
        "\n",
        "          # One-Hot Encoding\n",
        "          self.labels_enc = []\n",
        "          for l in labels:\n",
        "            l = 1 if l == 1 else 0\n",
        "            self.labels_enc.append(l)\n",
        "          self.labels_enc = torch.tensor(self.labels_enc)\n",
        "          self.labels_enc = self.labels_enc.to(device)\n",
        "\n",
        "          self.lines_enc = []\n",
        "          for l in lines:\n",
        "            X = torch.zeros(len(vocab) + 1)\n",
        "\n",
        "            for word in encode_sentence(l, vocab, use_tokenizer):\n",
        "              X[word] = 1\n",
        "            self.lines_enc.append(X)\n",
        "          self.lines_enc = [tensor.to(device) for tensor in self.lines_enc]\n",
        "\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not preload_to_gpu:\n",
        "          label, line = self.data[idx]\n",
        "          label = 1 if label == 1 else 0\n",
        "\n",
        "          # one-hot encoding\n",
        "          X = torch.zeros(len(self.vocab) + 1)\n",
        "              \n",
        "          for word in encode_sentence(line, self.vocab, use_tokenizer):\n",
        "              X[word] = 1\n",
        "\n",
        "          return X, torch.tensor(label)\n",
        "        else:\n",
        "          return self.lines_enc[idx], self.labels_enc[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amostras positivas, negativas e totais:\n",
            "Counter({'total': 25000, 'pos': 12500, 'neg': 12500})\n",
            "\n",
            "Quantidade média de palavras codificadas em cada vetor one-hot\n",
            "139.59268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load Data with One-hot Encoding\n",
        "train_data = IMDBDataset('train', vocab)\n",
        "test_data = IMDBDataset('test', vocab)\n",
        "\n",
        "# II.1.a) Investigue o dataset criado na linha 24. Faça um código que aplique um laço sobre o dataset train_data\n",
        "# e calcule novamente quantas amostras positivas e negativas do dataset.\n",
        "# II.1.b) Calcule também o número médio de palavras codificadas em cada vetor one-hot.\n",
        "# Compare este valor com o comprimento médio de cada texto (contado em palavras), conforme calculado no exercício\n",
        "\n",
        "counter_lbl = Counter({\"pos\": 0, \"neg\": 0, \"total\": 0})\n",
        "words_encoded = 0\n",
        "for (oneHot, sentiment) in train_data:\n",
        "\n",
        "    words = oneHot.tolist()\n",
        "    label = sentiment.item()\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    hot_encoded = sum(words[i] for i in range(len(words)) if words[i] != 0)\n",
        "    words_encoded +=  hot_encoded\n",
        "\n",
        "avg_words_enc = words_encoded / counter_lbl['total']\n",
        "\n",
        "print(\"Amostras positivas, negativas e totais:\")\n",
        "print(counter_lbl)\n",
        "print()\n",
        "\n",
        "print(\"Quantidade média de palavras codificadas em cada vetor one-hot\")\n",
        "print(avg_words_enc)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdM6ojduRqrw"
      },
      "source": [
        "#### II.1.b Compare este valor com o comprimento médio de cada texto (contado em palavras), conforme calculado no exercício I.1.c. e explique a diferença.\n",
        "\n",
        "No exercício I.1.c, o comprimento médio do texto em palavras depois de passar pelo tokenizador foi de cerca de 270 palavras. Essa diferença do vetor One-Hot se deve ao fato que o vetor one-hot só codifica as palavras que foram identificadas no dicionário, enquanto que o comprimento médio considera todas as palavras das sentenças. Ou seja, palavras que não foram codificadas no dicionário serão representadas por zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7RMPSvMDL5U"
      },
      "source": [
        "## III - Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y7tcZv2YDIog"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "# define dataloaders\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=train_shuffle)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwPeJ7h8DahT"
      },
      "source": [
        "## IV - Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6QuDhWvji7lt"
      },
      "outputs": [],
      "source": [
        "class OneHotMLP(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(OneHotMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(vocab_size+1, 200)\n",
        "        self.fc2 = nn.Linear(200, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        o = self.fc1(x.float())\n",
        "        o = self.relu(o)\n",
        "        return self.fc2(o)\n",
        "\n",
        "# Model instantiation\n",
        "model = OneHotMLP(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVAhdFGXDepU"
      },
      "source": [
        "## V - Laço de Treinamento - Otimização da função de Perda pelo Gradiente descendente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaH1Uv3yHih5",
        "outputId": "1658dbf7-719d-4cc5-840e-7694a626b24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU: NVIDIA GeForce RTX 2060\n"
          ]
        }
      ],
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "else:\n",
        "    print('using CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh_pe8rni93_",
        "outputId": "7c15ba5f-83a6-4288-f327-d21d74e12522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5],               Loss: 0.3748,               Elapsed Time: 4.23 sec\n",
            "Epoch [2/5],               Loss: 0.4524,               Elapsed Time: 0.57 sec\n",
            "Epoch [3/5],               Loss: 0.3885,               Elapsed Time: 0.56 sec\n",
            "Epoch [4/5],               Loss: 0.2724,               Elapsed Time: 0.55 sec\n",
            "Epoch [5/5],               Loss: 0.1962,               Elapsed Time: 0.57 sec\n"
          ]
        }
      ],
      "source": [
        "# II.2 Com a o notebook configurado para GPU T4, meça o tempo de dois laços dentro do\n",
        "# for da linha 13 (coloque um break após dois laços) e determine quanto demora\n",
        "# demora para o passo de forward (linhas 14 a 18), para o backward (linhas 20, 21 e 22)\n",
        "# e o tempo total de um laço. Faça as contas e identifique o trecho que é mais demorado.\n",
        "# II.2.a) Tempo do laço = ; Tempo do forward = ;Tempo do backward = ; Conclusão.\n",
        "\n",
        "import time\n",
        "\n",
        "# Transformando em função o treinamento\n",
        "def train_mdl(model, lr):\n",
        "  # Debug\n",
        "  print_loop = False\n",
        "\n",
        "  model = model.to(device)\n",
        "  # Define loss and optimizer\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr)\n",
        "\n",
        "  # Training loop\n",
        "  num_epochs = 5\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      start_time = time.time()  # Start time of the epoch\n",
        "      model.train()\n",
        "\n",
        "      loop_count = 0\n",
        "\n",
        "      for inputs, labels in train_loader:\n",
        "          loop_start = time.time()\n",
        "          if(loop_count == 2 and print_loop):\n",
        "            # Para medição do tempo do loop.\n",
        "            break\n",
        "\n",
        "          forward_start = time.time()\n",
        "          \n",
        "          if not preload_to_gpu:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "          \n",
        "          gpu_cpy_time = time.time() - forward_start\n",
        "          # Forward pass\n",
        "          model_start = time.time()\n",
        "          outputs = model(inputs)\n",
        "          model_time = time.time() - model_start\n",
        "          loss = criterion(outputs.squeeze(), labels.float())\n",
        "          forward_time = time.time() - forward_start\n",
        "\n",
        "          # Backward and optimize\n",
        "          backward_start = time.time()\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          backward_time = time.time() - backward_start\n",
        "\n",
        "          # Loop optimization\n",
        "          loop_count += 1\n",
        "          loop_time = time.time() - loop_start\n",
        "          if (epoch == 0 and print_loop):\n",
        "            print(\"Loop #\", loop_count)\n",
        "            print(\"Tempo de loop = \", loop_time)\n",
        "            print(\"Forward pass = \", forward_time)\n",
        "            gpu_percent = gpu_cpy_time/forward_time\n",
        "            print(\"Gpu copy = \" + str(gpu_percent*100) + \" %\")\n",
        "            print(\"Model processing = \" + str((1 - gpu_percent)*100) + \" %\")\n",
        "            print(\"Backward pass = \", backward_time)\n",
        "            print()\n",
        "\n",
        "      end_time = time.time()  # End time of the epoch\n",
        "      epoch_duration = end_time - start_time  # Duration of epoch\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
        "              Loss: {loss.item():.4f}, \\\n",
        "              Elapsed Time: {epoch_duration:.2f} sec')\n",
        "\n",
        "# Primeiro treinamento com a melhor taxa de Learning Rate \n",
        "train_mdl(model, best_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBswOILbX39h"
      },
      "source": [
        "##### II.2.a) Medição dos tempos de loop\n",
        "\n",
        "Notamos que o tempo do passo do forward leva mais tempo que o passo de backward, conforme os dados obtidos abaixo para a primeira época do treinamento.\n",
        "Também notamos que a maior parte to tempo do loop de forward é gasto com a transferência dos dados da CPU para a GPU (97% no primeiro loop).\n",
        "\n",
        "**Para 200 amostras**:\n",
        "\n",
        "```\n",
        "Loop # 1\n",
        "Tempo de loop =  0.048320770263671875\n",
        "Forward pass =  0.047322750091552734\n",
        "Gpu copy = 97.88851606662435 %\n",
        "Model processing = 2.1114839333756574 %\n",
        "Backward pass =  0.0009980201721191406\n",
        "\n",
        "Loop # 2\n",
        "Tempo de loop =  0.007141590118408203\n",
        "Forward pass =  0.005140781402587891\n",
        "Gpu copy = 80.50737408403673 %\n",
        "Model processing = 19.49262591596327 %\n",
        "Backward pass =  0.0020008087158203125\n",
        "```\n",
        "##### II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "\n",
        "Para otimizarmos o loop, o carregamento dos dados em GPU pode ser realizado pelo Dataloader fora do loop de treinamento, para tanto alterando o método __init__() da classe IMDBDataset.\n",
        "```\n",
        "def __init__(self, split, vocab):\n",
        "    #self.data = list(IMDB(split=split))[:n_samples]\n",
        "    self.data = list(balanced_dataset(IMDB(split=split), n_samples))        \n",
        "    self.vocab = vocab\n",
        "```\n",
        "##### II.2.c) Otimize o código e explique aqui.\n",
        "Substituimos então com a nova implementação, onde o dataset inteiro é pré-processado, codificado em forma One-Hot (uma vez que tensores não suportam strings) e movido para a GPU antes do processo de treinamento:\n",
        "````\n",
        "def __init__(self, split, vocab):\n",
        "    \n",
        "    # II.2.b) Trecho que precisa ser otimizado. (Esse é um problema mais difícil)\n",
        "    self.data = list(balanced_dataset(IMDB(split='train'), n_samples))\n",
        "\n",
        "    if preload_to_gpu:          \n",
        "        labels = [x[0] for x in self.data]\n",
        "        lines = [x[1] for x in self.data]\n",
        "\n",
        "        # One-Hot Encoding\n",
        "        self.labels_enc = []\n",
        "        for l in labels:\n",
        "        l = 1 if l == 1 else 0\n",
        "        self.labels_enc.append(l)\n",
        "        self.labels_enc = torch.tensor(self.labels_enc)\n",
        "        self.labels_enc = self.labels_enc.to(device)\n",
        "\n",
        "        self.lines_enc = []\n",
        "        for l in lines:\n",
        "        X = torch.zeros(len(vocab) + 1)\n",
        "        for word in encode_sentence(l, vocab):\n",
        "            X[word] = 1\n",
        "        self.lines_enc.append(X)\n",
        "        self.lines_enc = [tensor.to(device) for tensor in self.lines_enc]\n",
        "\n",
        "    self.vocab = vocab\n",
        "````\n",
        "##### Comparação do tempo de treinamento com a otimização (GPU RTX2060 local):\n",
        "Sem pre-load em GPU:\n",
        "````\n",
        "Epoch [1/5],             Loss: 0.6911,             Elapsed Time: 61.36 sec\n",
        "Epoch [2/5],             Loss: 0.6929,             Elapsed Time: 58.69 sec\n",
        "Epoch [3/5],             Loss: 0.6984,             Elapsed Time: 58.95 sec\n",
        "Epoch [4/5],             Loss: 0.6792,             Elapsed Time: 58.60 sec\n",
        "Epoch [5/5],             Loss: 0.6874,             Elapsed Time: 58.59 sec\n",
        "````\n",
        "Com pre-load em GPU (RTX2060)\n",
        "````\n",
        "Epoch [1/5],             Loss: 0.6896,             Elapsed Time: 3.81 sec\n",
        "Epoch [2/5],             Loss: 0.6925,             Elapsed Time: 0.58 sec\n",
        "Epoch [3/5],             Loss: 0.6933,             Elapsed Time: 0.64 sec\n",
        "Epoch [4/5],             Loss: 0.6890,             Elapsed Time: 0.58 sec\n",
        "Epoch [5/5],             Loss: 0.6904,             Elapsed Time: 0.57 sec\n",
        "````\n",
        "Notamos, no entanto, que o uso de mémória na GPU se torna muito maior, conforme pode ser visualizado abaixo (5Gb/6Gb total):\n",
        "````\n",
        "[venv:ml] $ nvidia-smi\n",
        "Mon Feb 12 08:23:42 2024\n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
        "| N/A   76C    P8    12W /  N/A |   5035MiB /  6144MiB |      1%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwvahen5D1oM"
      },
      "source": [
        "## VI - Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DtTPUBfjBj-",
        "outputId": "92800f0b-d653-40d3-c9cf-603f1b15415d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 92.732%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "92.732"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## evaluation\n",
        "def eval_mdl(model):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.round(torch.sigmoid(outputs.squeeze()))\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100* correct/total\n",
        "        print(f'Test Accuracy: {acc}%')\n",
        "    return acc\n",
        "\n",
        "eval_mdl(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### II.3 Faça a melhor escolha do LR, analisando o valor da acurácia no conjunto de teste, utilizando para cada valor de LR, a acurácia obtida. Faça um gráfico de Acurácia vs LR e escolha o LR que forneça a maior acurácia possível."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR =  0.0001\n",
            "Epoch [1/5],               Loss: 0.6944,               Elapsed Time: 0.56 sec\n",
            "Epoch [2/5],               Loss: 0.6926,               Elapsed Time: 0.56 sec\n",
            "Epoch [3/5],               Loss: 0.6920,               Elapsed Time: 0.57 sec\n",
            "Epoch [4/5],               Loss: 0.6989,               Elapsed Time: 0.55 sec\n",
            "Epoch [5/5],               Loss: 0.6949,               Elapsed Time: 0.57 sec\n",
            "Test Accuracy: 50.04%\n",
            "\n",
            "LR =  0.001\n",
            "Epoch [1/5],               Loss: 0.6935,               Elapsed Time: 0.57 sec\n",
            "Epoch [2/5],               Loss: 0.6908,               Elapsed Time: 0.56 sec\n",
            "Epoch [3/5],               Loss: 0.6847,               Elapsed Time: 0.55 sec\n",
            "Epoch [4/5],               Loss: 0.6868,               Elapsed Time: 0.56 sec\n",
            "Epoch [5/5],               Loss: 0.6809,               Elapsed Time: 0.55 sec\n",
            "Test Accuracy: 69.52%\n",
            "\n",
            "LR =  0.01\n",
            "Epoch [1/5],               Loss: 0.6780,               Elapsed Time: 0.56 sec\n",
            "Epoch [2/5],               Loss: 0.6182,               Elapsed Time: 0.57 sec\n",
            "Epoch [3/5],               Loss: 0.6178,               Elapsed Time: 0.56 sec\n",
            "Epoch [4/5],               Loss: 0.5255,               Elapsed Time: 0.56 sec\n",
            "Epoch [5/5],               Loss: 0.4993,               Elapsed Time: 0.56 sec\n",
            "Test Accuracy: 82.796%\n",
            "\n",
            "LR =  0.1\n",
            "Epoch [1/5],               Loss: 0.3486,               Elapsed Time: 0.57 sec\n",
            "Epoch [2/5],               Loss: 0.3932,               Elapsed Time: 0.54 sec\n",
            "Epoch [3/5],               Loss: 0.2327,               Elapsed Time: 0.55 sec\n",
            "Epoch [4/5],               Loss: 0.1785,               Elapsed Time: 0.54 sec\n",
            "Epoch [5/5],               Loss: 0.4020,               Elapsed Time: 0.55 sec\n",
            "Test Accuracy: 70.74%\n",
            "\n",
            "LR =  0.5\n",
            "Epoch [1/5],               Loss: 0.6660,               Elapsed Time: 0.56 sec\n",
            "Epoch [2/5],               Loss: 0.3109,               Elapsed Time: 0.56 sec\n",
            "Epoch [3/5],               Loss: 0.1137,               Elapsed Time: 0.55 sec\n",
            "Epoch [4/5],               Loss: 0.1693,               Elapsed Time: 0.56 sec\n",
            "Epoch [5/5],               Loss: 0.1881,               Elapsed Time: 0.55 sec\n",
            "Test Accuracy: 92.748%\n",
            "\n",
            "LR =  1\n",
            "Epoch [1/5],               Loss: 0.6869,               Elapsed Time: 0.56 sec\n",
            "Epoch [2/5],               Loss: 0.5617,               Elapsed Time: 0.54 sec\n",
            "Epoch [3/5],               Loss: 0.6670,               Elapsed Time: 0.54 sec\n",
            "Epoch [4/5],               Loss: 0.8445,               Elapsed Time: 0.55 sec\n",
            "Epoch [5/5],               Loss: 0.2390,               Elapsed Time: 0.55 sec\n",
            "Test Accuracy: 90.7%\n",
            "\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.5, 1]\n",
            "[50.04, 69.52, 82.796, 70.74, 92.748, 90.7]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_list = [0.0001, 0.001, 0.01, 0.1, 0.5, 1]\n",
        "acc_list = []\n",
        "\n",
        "for lr in lr_list:\n",
        "    print(\"LR = \", lr)\n",
        "    model = OneHotMLP(vocab_size) # to reset weights \n",
        "    train_mdl(model, lr)\n",
        "    acc_list.append(eval_mdl(model))\n",
        "    print()\n",
        "\n",
        "print(lr_list)\n",
        "print(acc_list)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### II.3.a) Gráfico Acurácia vs LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.lineplot(x=lr_list, y=acc_list)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs Learning Rate\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### II.3.b) Valor ótimo do LR\n",
        "\n",
        "Notamos que o valor ótimo para a Learning Rate foi de cerca de 0.5, com crescimento exponencial ao aumentá-la. Valores acima deste são grandes demais e não levam à otimização do modelo.\n",
        "\n",
        "##### II.3.c) Mostre a equação utilizada no gradiente descendente e qual é o papel do LR no ajuste dos parâmetros (weights) do modelo da rede neural.\n",
        "\n",
        "No processo de otimização de uma função, a fórmula utilizada para a estimativa do próximo valor da função é dada por:\n",
        "\n",
        "````\n",
        "valor atualizado = valor anterior - learning rate*gradiente\n",
        "`````\n",
        "\n",
        "Portanto o papel da LR é definir qual é o *tamanho* do passo a ser utilizado no processo de atualização."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### II.4 Melhores a forma de tokenizar, isto é, pré-processar o dataset de modo que a codificação seja indiferente das palavras serem escritas com maiúsculas ou minúsculas e sejam pouco influenciadas pelas pontuações.\n",
        "##### II.4.a) Mostre os trechos modificados para este novo tokenizador, tanto na seção I - Vocabulário, como na seção II - Dataset.\n",
        "\n",
        "Na seção I - Vocabulário:\n",
        "\n",
        "````\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "for (label, line) in list(IMDB(split='train'))[:n_samples]:\n",
        "    if (use_tokenizer):\n",
        "      tokenizer = get_tokenizer('basic_english')\n",
        "      # tokenize the sentence\n",
        "      line = tokenizer(line)\n",
        "    counter.update(line.split())\n",
        "\n",
        "    # Número de amostras positivas e negativas\n",
        "    if (label == 1):\n",
        "      counter_lbl['neg'] += 1\n",
        "    else:\n",
        "      counter_lbl['pos'] += 1\n",
        "    counter_lbl['total'] += 1\n",
        "\n",
        "    # Comprimento médio do texto das reviews em palavras\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    # tokenize the sentence\n",
        "    tokens = tokenizer(line)\n",
        "\n",
        "    # count the number of words\n",
        "    total_review_len += len(tokens)\n",
        "\n",
        "````\n",
        "\n",
        "Na Seção II - Dataset:\n",
        "São apenas necessárias alterações no encoder da sentença, conforme abaixo.\n",
        "\n",
        "````\n",
        "def encode_sentence(sentence, vocab, use_tokenizer):\n",
        "    if (use_tokenizer):\n",
        "       sentence = tokenizer(sentence)\n",
        "       return [vocab.get(word, 0) for word in sentence]\n",
        "    else:\n",
        "      return [vocab.get(word, 0) for word in sentence.split()] # 0 for OOV\n",
        "````\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### II.4.b) Recalcule novamente os valores do exercício I.2.c - número de tokens unknown, e apresente uma tabela comparando os novos valores com os valores obtidos com o tokenizador original e justifique os resultados obtidos.\n",
        "\n",
        "Sem o tokenizador:\n",
        "\n",
        "566141\n",
        "\n",
        "Com o tokenizador:\n",
        "\n",
        "174226\n",
        "\n",
        "Estes valores se justificam pelo fato que o tokenizador altera as palavras das sentenças, mantendo apenas radicais, de forma que menos palavras não serão encontradas na base do vocabulário.\n",
        "\n",
        "\n",
        "##### II.4.c) Execute agora no notebook inteiro com o novo tokenizador e veja o novo valor da acurácia obtido com a melhoria do tokenizador.\n",
        "\n",
        "Sem o tokenizador:\n",
        "\n",
        "Test Accuracy: 60.39% (Para LR = 0.5)\n",
        "\n",
        "Com o tokenizador \n",
        "\n",
        "Test Accuracy: 92.74% (Para LR = 0.5)\n",
        "\n",
        "O aumento da acurácia é justificado pelo fato que menos palavras de cada sentença não serão reconhecidas (OneHot encoding não terá tantos valores zerados)\n",
        "\n",
        "##### Os dados obtidos estão resumidos na tabela abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uso do Tokenizador      Tokens Unknown  Test Accuracy\n",
            "--------------------  ----------------  ---------------\n",
            "Sem Tokenizador                 566141  60.39%\n",
            "Com Tokenizador                 174226  92.74%\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    ['Sem Tokenizador', 566141, '60.39%'],\n",
        "    ['Com Tokenizador', 174226, '92.74%'],\n",
        "]\n",
        "\n",
        "# Headers\n",
        "headers = ['Uso do Tokenizador', 'Tokens Unknown', 'Test Accuracy']\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(data, headers=headers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Seção III\n",
        "\n",
        "##### Vamos estudar agora o Data Loader da seção III do notebook. Em primeiro lugar anote a acurácia do notebook com as melhorias de eficiência de rodar em GPU, com ajustes de LR e do tokenizador. Em seguida mude o parâmetro shuffle na construção do objeto train_loader para False e execute novamente o notebook por completo e meça novamente a acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shuffle dos dados de Treinamento    Test Accuracy\n",
            "----------------------------------  ---------------\n",
            "Com Shuffle                         92.74%\n",
            "Sem Shuffle                         x\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    ['Com Shuffle', '92.74%'],\n",
        "    ['Sem Shuffle', 'x']\n",
        "]\n",
        "\n",
        "# Headers\n",
        "headers = ['Shuffle dos dados de Treinamento', 'Test Accuracy']\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(data, headers=headers))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IA024",
      "language": "python",
      "name": "ia024"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
