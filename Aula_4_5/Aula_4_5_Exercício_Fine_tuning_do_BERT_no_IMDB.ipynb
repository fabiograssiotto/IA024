{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OG5DT_dm6mk"
      },
      "source": [
        "# Notebook de referência\n",
        "\n",
        "Nome: Fabio Grassiotto RA 890441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ80hHaftwUd"
      },
      "source": [
        "## Instruções:\n",
        "\n",
        "\n",
        "Treinar e medir a acurácia de um modelo BERT (ou variantes) para classificação binária usando o dataset do IMDB (20k/5k amostras de treino/validação).\n",
        "\n",
        "Importante:\n",
        "- Deve-se implementar o próprio laço de treinamento.\n",
        "- Implementar o acumulo de gradiente.\n",
        "\n",
        "Dicas:\n",
        "- BERT geralmente costuma aprender bem uma tarefa com poucas épocas (de 3 a 5 épocas). Se tiver demorando mais de 5 épocas para chegar em 80% de acurácia, ajuste os hiperparametros.\n",
        "\n",
        "- Solução para erro de memória:\n",
        "  - Usar bfloat16 permite quase dobrar o batch size\n",
        "\n",
        "Opcional:\n",
        "- Pode-se usar a função trainer da biblioteca Transformers/HuggingFace para verificar se seu laço de treinamento está correto. Note que ainda assim é obrigatório implementar o laço próprio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install transformers[torch]\n",
        "%pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1ozXD-xYCcrT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variáveis Globais e inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Seed\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Load Models from filesystem\n",
        "LOAD_PRETRAINED = True\n",
        "LOAD_HUGFACE = True\n",
        "LOAD_LOOP = False\n",
        "\n",
        "# Colab environment\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if (IN_COLAB):\n",
        "    # Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    project_folder=\"/content/drive/MyDrive/Classes/IA024/Aula_4_5\"\n",
        "    os.chdir(project_folder)\n",
        "    !ls -la\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFdJz2KVeQw"
      },
      "source": [
        "## Preparando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMi_Kq65fPM"
      },
      "source": [
        "Primeiro, fazemos download do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wbnfzst5O3k",
        "outputId": "bebda5c0-5614-4cd0-a2f4-5754cdb9c336"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"aclImdb.tgz\"):\n",
        "    print(\"Downloading Imdb dataset\")\n",
        "    !wget -nc http://files.fast.ai/data/aclImdb.tgz\n",
        "    !tar -xzf aclImdb.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Giyi5Rv_NIm"
      },
      "source": [
        "## Carregando o dataset\n",
        "\n",
        "Criaremos uma divisão de treino (20k exemplos) e validação (5k exemplos) artificialmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HIN_xLI_TuT",
        "outputId": "787fc595-88b1-486a-8c0c-bcde36396793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20000 amostras de treino.\n",
            "5000 amostras de desenvolvimento.\n",
            "25000 amostras de teste.\n",
            "3 primeiras amostras treino:\n",
            "0 POSSIBLE SPOILERS<br /><br />The Spy Who Shagged Me is a muchly overrated and over-hyped sequel. Int\n",
            "0 The long list of \"big\" names in this flick (including the ubiquitous John Mills) didn't bowl me over\n",
            "1 Bette Midler showcases her talents and beauty in \"Diva Las Vegas\". I am thrilled that I taped it and\n",
            "3 últimas amostras treino:\n",
            "0 I was previously unaware that in the early 1990's Devry University (or was it ITT Tech?) added Film \n",
            "1 The story and music (George Gershwin!) are wonderful, as are Levant, Guetary, Foch, and, of course, \n",
            "1 This is my favorite show. I think it is utterly brilliant. Thanks to David Chase for bringing this i\n",
            "3 primeiras amostras validação:\n",
            "1 Why has this not been released? I kind of thought it must be a bit rubbish since it hasn't been. How\n",
            "1 I was amazingly impressed by this movie. It contained fundamental elements of depression, grief, lon\n",
            "1 photography was too jumpy to follow. dark scenes hard to see.<br /><br />Had good story line too bad\n",
            "3 últimas amostras validação:\n",
            "1 In the early to mid 1970's, Clifford Irving proposed to write the ultimate biography of Howard Hughe\n",
            "1 An ultra-modern house in an affluent neighborhood appears to be the cause of each of its inhabitants\n",
            "1 Some of the best movies that are categorized as \"comedies\" actually blur between comedy and drama. \"\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "max_valid = 5000\n",
        "\n",
        "def load_texts(folder):\n",
        "    texts = []\n",
        "    for path in os.listdir(folder):\n",
        "        with open(os.path.join(folder, path)) as f:\n",
        "            texts.append(f.read())\n",
        "    return texts\n",
        "\n",
        "x_train_pos = load_texts('aclImdb/train/pos')\n",
        "x_train_neg = load_texts('aclImdb/train/neg')\n",
        "x_test_pos = load_texts('aclImdb/test/pos')\n",
        "x_test_neg = load_texts('aclImdb/test/neg')\n",
        "\n",
        "x_train = x_train_pos + x_train_neg\n",
        "x_test = x_test_pos + x_test_neg\n",
        "#y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n",
        "#y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n",
        "# Use 0/1 for classes\n",
        "y_train = [1] * len(x_train_pos) + [0] * len(x_train_pos)\n",
        "y_test = [1] * len(x_test_pos) + [0] * len(x_test_pos)\n",
        "\n",
        "# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n",
        "c = list(zip(x_train, y_train))\n",
        "random.shuffle(c)\n",
        "x_train, y_train = zip(*c)\n",
        "\n",
        "x_valid = x_train[-max_valid:]\n",
        "y_valid = y_train[-max_valid:]\n",
        "x_train = x_train[:-max_valid]\n",
        "y_train = y_train[:-max_valid]\n",
        "\n",
        "print(len(x_train), 'amostras de treino.')\n",
        "print(len(x_valid), 'amostras de desenvolvimento.')\n",
        "print(len(x_test), 'amostras de teste.')\n",
        "\n",
        "print('3 primeiras amostras treino:')\n",
        "for x, y in zip(x_train[:3], y_train[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras treino:')\n",
        "for x, y in zip(x_train[-3:], y_train[-3:]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 primeiras amostras validação:')\n",
        "for x, y in zip(x_valid[:3], y_test[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras validação:')\n",
        "for x, y in zip(x_valid[-3:], y_valid[-3:]):\n",
        "    print(y, x[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POSSIBLE SPOILERS<br /><br />The Spy Who Shagged Me is a muchly overrated and over-hyped sequel. International Man of Mystery came straight out of the blue. It was a lone star that few people had heard of. But it was stunningly original, had sophisticated humour and ample humour, always kept in good taste, and had a brilliant cast. The Spy Who Shagged Me was a lot more commercially advertised and hyped about.<br /><br />OK I'll admit, the first time I saw this film I thought it was very funny, but it's only after watching it two or three times that you see all the flaws. The acting was OK, but Heather Graham cannot act. Her performance didn't seem very convincing and she wasn't near as good as Liz Hurley was in the first one. Those characters who bloomed in the first one, (Scott Evil, Number 2 etc.) are thrown into the background hear and don't get many stand-alone scenes. The film is simply overrun with cameos.<br /><br />In particular, I hated the way they totally disregarded some of the scenes in IMOM. When they killed off Vanessa at the start and had Basil sat that he knew she was a fembot all along. What was the point of that? They killed off Number 2 in the first one, and now they bring him back with no explanation whatsoever. This is supposed to be a spy-spoof, I don't think any of the characters even hold a gun in the film. It just goes on a trail, further and further away from the point.<br /><br />The new characters are very unwelcome. The whole Mini-Me `make fun of my size' joke gets old very quickly. Fat Bastard is just a lame excuse for gross-out humour. In total there's about two or three good jokes. The rest are either tasteless or rehashed from IMOM.<br /><br />If this were the first movie of the series then I'd probably be easier on it. But the series started on a note of dry wit and then plummeted down to a level of gross out humour. So I say, only watch this film if you haven't seen its predecessor, because The Spy Who Shagged Me is one ultimate disappointment.\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Checking output\n",
        "print(x_train[0])\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tokenização do dataset\n",
        "#### Nota: O código abaixo tomou como base o tutorial \"How to Fine Tune BERT for Text Classification using Transformers in Python\" em https://thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python para a utilização das APIs do HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (LOAD_PRETRAINED):# Bert base model\n",
        "    model_path = \"model/pretrained\"\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "else:    \n",
        "    model_name = \"bert-base-uncased\"\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# max sequence length\n",
        "max_length = 512\n",
        "\n",
        "train_encodings = tokenizer(x_train, truncation=True, padding=True, max_length=max_length)\n",
        "valid_encodings = tokenizer(x_valid, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings = tokenizer(x_test, truncation=True, padding=True, max_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ]
        }
      ],
      "source": [
        "print(train_encodings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classe do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImdbDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "train_dataset = ImdbDataset(train_encodings, y_train)\n",
        "valid_dataset = ImdbDataset(valid_encodings, y_valid)\n",
        "test_dataset = ImdbDataset(test_encodings, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo do HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (LOAD_PRETRAINED):# Bert base model\n",
        "    model_path = \"model/pretrained\"\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path, local_files_only=True).to(device)\n",
        "else:\n",
        "    model_name = \"bert-base-uncased\"\n",
        "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
        "\n",
        "    # saving the pre-trained model and tokenizer\n",
        "    pretrained_path = \"model/pretrained\"\n",
        "    model.save_pretrained(pretrained_path)\n",
        "    tokenizer.save_pretrained(pretrained_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treinamento e Avaliação do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Com Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "epochs = 3\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "def train_loop(model, optimizer, device):\n",
        "      # Training Loop\n",
        "      model.train()\n",
        "      for epoch in range(epochs):\n",
        "            for batch in tqdm(train_loader):\n",
        "                  batch = {k: v.cuda() for k, v in batch.items()}\n",
        "                  \n",
        "                  # Forward pass\n",
        "                  outputs = model(**batch)\n",
        "                  loss = outputs.loss\n",
        "\n",
        "                  # Backward pass and optimization\n",
        "                  optimizer.zero_grad()\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2500/2500 [07:24<00:00,  5.62it/s]\n",
            " 14%|█▍        | 353/2500 [01:02<06:28,  5.53it/s]"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
        "\n",
        "model_path = \"model/loop\"\n",
        "if (LOAD_LOOP):    \n",
        "    model = BertForSequenceClassification.from_pretrained(model_path, local_files_only=True).to(device)\n",
        "else:  \n",
        "    train_loop(model, optimizer, device)\n",
        "    # saving the fine tuned model\n",
        "    model.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval(model):\n",
        "    model.eval()\n",
        "\n",
        "    loss_sum = 0\n",
        "    total_sum = 0\n",
        "    correct_sum = 0\n",
        "    eval_round = 0\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader):\n",
        "            batch = {k: v.cuda() for k, v in batch.items()}\n",
        "            targets = batch['labels']\n",
        "\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss   \n",
        "\n",
        "            loss_sum += loss\n",
        "\n",
        "            # Get the predicted labels\n",
        "            predicted = torch.max(outputs[0], -1)\n",
        "\n",
        "            total_sum += targets.size(0)\n",
        "            correct_sum += (predicted == targets).sum().item()\n",
        "            eval_round += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    acc = 100 * correct_sum / total_sum\n",
        "\n",
        "    # Calculate average perplexity\n",
        "    average_loss = loss_sum / len(val_loader)\n",
        "    average_perplexity = torch.exp(average_loss)\n",
        "\n",
        "    print(f'Test Accuracy: {acc:.2f}%')\n",
        "    print(f'Average Loss: {average_loss:.2f}')\n",
        "    print(f'Average Perplexity: {average_perplexity:.2f}')\n",
        "\n",
        "eval(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Biblioteca HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    save_strategy=\"epoch\",              # Do not save intermediary steps\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # Model\n",
        "    args=training_args,                  # training args\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=valid_dataset,          # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        ")\n",
        "\n",
        "model_path = \"model/hf\"\n",
        "if (LOAD_HUGFACE):    \n",
        "    model = BertForSequenceClassification.from_pretrained(model_path, local_files_only=True).to(device)\n",
        "else:  \n",
        "    trainer.train()\n",
        "    # saving the fine tuned model\n",
        "    model.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Avaliação do Modelo (base de validação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate the current model after training\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Avaliação do Modelo (base de teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testando inferência com textos comuns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    return target_names[probs.argmax()]\n",
        "\n",
        "test_neg = \"This movie was like the worst thing ever.\"\n",
        "test_pos_1 = \"One of this generation's best\"\n",
        "test_pos_2 = \"This is a movie to die for.\"\n",
        "\n",
        "print(\"Testing predictions:\\n\")\n",
        "print(f'{test_neg} => {get_prediction(test_neg)}')\n",
        "print(f'{test_pos_1} => {get_prediction(test_pos_1)}')\n",
        "print(f'{test_pos_2} => {get_prediction(test_pos_2)}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
