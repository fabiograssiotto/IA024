{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OG5DT_dm6mk"
      },
      "source": [
        "# Notebook de referência\n",
        "\n",
        "Nome: Fabio Grassiotto RA 890441"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ80hHaftwUd"
      },
      "source": [
        "## Instruções:\n",
        "\n",
        "\n",
        "Treinar e medir a acurácia de um modelo BERT (ou variantes) para classificação binária usando o dataset do IMDB (20k/5k amostras de treino/validação).\n",
        "\n",
        "Importante:\n",
        "- Deve-se implementar o próprio laço de treinamento.\n",
        "- Implementar o acumulo de gradiente.\n",
        "\n",
        "Dicas:\n",
        "- BERT geralmente costuma aprender bem uma tarefa com poucas épocas (de 3 a 5 épocas). Se tiver demorando mais de 5 épocas para chegar em 80% de acurácia, ajuste os hiperparametros.\n",
        "\n",
        "- Solução para erro de memória:\n",
        "  - Usar bfloat16 permite quase dobrar o batch size\n",
        "\n",
        "Opcional:\n",
        "- Pode-se usar a função trainer da biblioteca Transformers/HuggingFace para verificar se seu laço de treinamento está correto. Note que ainda assim é obrigatório implementar o laço próprio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (4.39.3)\n",
            "Requirement already satisfied: filelock in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (2.2.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from transformers[torch]) (0.29.1)\n",
            "Requirement already satisfied: psutil in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: colorama in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: accelerate in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate) (2.2.1)\n",
            "Requirement already satisfied: huggingface-hub in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
            "Requirement already satisfied: requests in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: colorama in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in d:\\development\\conda-envs\\ml_pytorch\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers[torch]\n",
        "%pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1ozXD-xYCcrT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variáveis Globais e inicialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Seed\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Training \n",
        "TRAIN_HUGFACE = False\n",
        "TRAIN_LOOP = True\n",
        "\n",
        "# Colab environment\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if (IN_COLAB):\n",
        "    # Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    project_folder=\"/content/drive/MyDrive/Classes/IA024/Aula_4_5\"\n",
        "    os.chdir(project_folder)\n",
        "    !ls -la\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFdJz2KVeQw"
      },
      "source": [
        "## Preparando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMi_Kq65fPM"
      },
      "source": [
        "Primeiro, fazemos download do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wbnfzst5O3k",
        "outputId": "bebda5c0-5614-4cd0-a2f4-5754cdb9c336"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"aclImdb.tgz\"):\n",
        "    print(\"Downloading Imdb dataset\")\n",
        "    !wget -nc http://files.fast.ai/data/aclImdb.tgz\n",
        "    !tar -xzf aclImdb.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Giyi5Rv_NIm"
      },
      "source": [
        "## Carregando o dataset\n",
        "\n",
        "Criaremos uma divisão de treino (20k exemplos) e validação (5k exemplos) artificialmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HIN_xLI_TuT",
        "outputId": "787fc595-88b1-486a-8c0c-bcde36396793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20000 amostras de treino.\n",
            "5000 amostras de desenvolvimento.\n",
            "25000 amostras de teste.\n",
            "3 primeiras amostras treino:\n",
            "0 POSSIBLE SPOILERS<br /><br />The Spy Who Shagged Me is a muchly overrated and over-hyped sequel. Int\n",
            "0 The long list of \"big\" names in this flick (including the ubiquitous John Mills) didn't bowl me over\n",
            "1 Bette Midler showcases her talents and beauty in \"Diva Las Vegas\". I am thrilled that I taped it and\n",
            "3 últimas amostras treino:\n",
            "0 I was previously unaware that in the early 1990's Devry University (or was it ITT Tech?) added Film \n",
            "1 The story and music (George Gershwin!) are wonderful, as are Levant, Guetary, Foch, and, of course, \n",
            "1 This is my favorite show. I think it is utterly brilliant. Thanks to David Chase for bringing this i\n",
            "3 primeiras amostras validação:\n",
            "1 Why has this not been released? I kind of thought it must be a bit rubbish since it hasn't been. How\n",
            "1 I was amazingly impressed by this movie. It contained fundamental elements of depression, grief, lon\n",
            "1 photography was too jumpy to follow. dark scenes hard to see.<br /><br />Had good story line too bad\n",
            "3 últimas amostras validação:\n",
            "1 In the early to mid 1970's, Clifford Irving proposed to write the ultimate biography of Howard Hughe\n",
            "1 An ultra-modern house in an affluent neighborhood appears to be the cause of each of its inhabitants\n",
            "1 Some of the best movies that are categorized as \"comedies\" actually blur between comedy and drama. \"\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "max_valid = 5000\n",
        "\n",
        "def load_texts(folder):\n",
        "    texts = []\n",
        "    for path in os.listdir(folder):\n",
        "        with open(os.path.join(folder, path)) as f:\n",
        "            texts.append(f.read())\n",
        "    return texts\n",
        "\n",
        "x_train_pos = load_texts('aclImdb/train/pos')\n",
        "x_train_neg = load_texts('aclImdb/train/neg')\n",
        "x_test_pos = load_texts('aclImdb/test/pos')\n",
        "x_test_neg = load_texts('aclImdb/test/neg')\n",
        "\n",
        "x_train = x_train_pos + x_train_neg\n",
        "x_test = x_test_pos + x_test_neg\n",
        "#y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n",
        "#y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n",
        "y_train = [1] * len(x_train_pos) + [0] * len(x_train_pos)\n",
        "y_test = [1] * len(x_test_pos) + [0] * len(x_test_pos)\n",
        "\n",
        "# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n",
        "c = list(zip(x_train, y_train))\n",
        "random.shuffle(c)\n",
        "x_train, y_train = zip(*c)\n",
        "\n",
        "x_valid = x_train[-max_valid:]\n",
        "y_valid = y_train[-max_valid:]\n",
        "x_train = x_train[:-max_valid]\n",
        "y_train = y_train[:-max_valid]\n",
        "\n",
        "print(len(x_train), 'amostras de treino.')\n",
        "print(len(x_valid), 'amostras de desenvolvimento.')\n",
        "print(len(x_test), 'amostras de teste.')\n",
        "\n",
        "print('3 primeiras amostras treino:')\n",
        "for x, y in zip(x_train[:3], y_train[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras treino:')\n",
        "for x, y in zip(x_train[-3:], y_train[-3:]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 primeiras amostras validação:')\n",
        "for x, y in zip(x_valid[:3], y_test[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras validação:')\n",
        "for x, y in zip(x_valid[-3:], y_valid[-3:]):\n",
        "    print(y, x[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POSSIBLE SPOILERS<br /><br />The Spy Who Shagged Me is a muchly overrated and over-hyped sequel. International Man of Mystery came straight out of the blue. It was a lone star that few people had heard of. But it was stunningly original, had sophisticated humour and ample humour, always kept in good taste, and had a brilliant cast. The Spy Who Shagged Me was a lot more commercially advertised and hyped about.<br /><br />OK I'll admit, the first time I saw this film I thought it was very funny, but it's only after watching it two or three times that you see all the flaws. The acting was OK, but Heather Graham cannot act. Her performance didn't seem very convincing and she wasn't near as good as Liz Hurley was in the first one. Those characters who bloomed in the first one, (Scott Evil, Number 2 etc.) are thrown into the background hear and don't get many stand-alone scenes. The film is simply overrun with cameos.<br /><br />In particular, I hated the way they totally disregarded some of the scenes in IMOM. When they killed off Vanessa at the start and had Basil sat that he knew she was a fembot all along. What was the point of that? They killed off Number 2 in the first one, and now they bring him back with no explanation whatsoever. This is supposed to be a spy-spoof, I don't think any of the characters even hold a gun in the film. It just goes on a trail, further and further away from the point.<br /><br />The new characters are very unwelcome. The whole Mini-Me `make fun of my size' joke gets old very quickly. Fat Bastard is just a lame excuse for gross-out humour. In total there's about two or three good jokes. The rest are either tasteless or rehashed from IMOM.<br /><br />If this were the first movie of the series then I'd probably be easier on it. But the series started on a note of dry wit and then plummeted down to a level of gross out humour. So I say, only watch this film if you haven't seen its predecessor, because The Spy Who Shagged Me is one ultimate disappointment.\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tokenização do dataset\n",
        "### Nota: O código abaixo é basead no tutorial \"How to Fine Tune BERT for Text Classification using Transformers in Python\" em https://thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python. O modelo foi fine-tuned em GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bert base model\n",
        "model_name = \"bert-base-uncased\"\n",
        "# max sequence length\n",
        "max_length = 512\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(x_train, truncation=True, padding=True, max_length=max_length)\n",
        "valid_encodings = tokenizer(x_valid, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings = tokenizer(x_test, truncation=True, padding=True, max_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ]
        }
      ],
      "source": [
        "print(train_encodings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classe do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImdbDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "train_dataset = ImdbDataset(train_encodings, y_train)\n",
        "valid_dataset = ImdbDataset(valid_encodings, y_valid)\n",
        "test_dataset = ImdbDataset(test_encodings, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo do HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('model/pretrained\\\\tokenizer_config.json',\n",
              " 'model/pretrained\\\\special_tokens_map.json',\n",
              " 'model/pretrained\\\\vocab.txt',\n",
              " 'model/pretrained\\\\added_tokens.json',\n",
              " 'model/pretrained\\\\tokenizer.json')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
        "\n",
        "# saving the pre-trained model and tokenizer\n",
        "pretrained_path = \"model/pretrained\"\n",
        "model.save_pretrained(pretrained_path)\n",
        "tokenizer.save_pretrained(pretrained_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Com Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  2001,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2018,  ...,     0,     0,     0],\n",
            "        [  101, 13970,  7352,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  1037,  2186,  ...,     0,     0,     0],\n",
            "        [  101,  2026,  2034,  ...,     0,     0,     0],\n",
            "        [  101,  2023,  2003,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0]])}\n"
          ]
        }
      ],
      "source": [
        "batch_size = 20\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "sample = next(iter(train_loader))\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 3\n",
        "\n",
        "def train_loop(model, criterion, optimizer, device):\n",
        "      # Training Loop\n",
        "      model.train()\n",
        "      for epoch in range(epochs):\n",
        "\n",
        "            epoch_start = time.time()\n",
        "            # Metrics\n",
        "            epoch_loss = 0\n",
        "            epoch_correct = 0\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for inputs, targets in train_loader:\n",
        "                  inputs = inputs.to(device)  # Move input data to the device\n",
        "                  targets = targets.to(device)\n",
        "\n",
        "                  # Forward pass\n",
        "                  logits = model(inputs)\n",
        "                  loss = criterion(logits, targets)\n",
        "\n",
        "                  # Backward pass and optimization\n",
        "                  optimizer.zero_grad()\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "                  # Loss\n",
        "                  epoch_loss += loss.item()\n",
        "\n",
        "                  # Predicted\n",
        "                  _, predicted = torch.max(logits, 1)\n",
        "                  epoch_correct += (predicted == targets).sum().item()\n",
        "                  epoch_samples += targets.size(0)\n",
        "\n",
        "            # Calculate average loss and accuracy for epoch\n",
        "            avg_loss = epoch_loss / len(train_loader)\n",
        "            acc = epoch_correct / epoch_samples\n",
        "\n",
        "            # Perplexity\n",
        "            perp = torch.exp(torch.tensor(avg_loss))\n",
        "\n",
        "            epoch_end = time.time()\n",
        "            epoch_time = epoch_end - epoch_start\n",
        "            # Print epoch statistics\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Time:{epoch_time:.2f}, Loss: {avg_loss:.4f}, Accuracy: {acc:.2f}%, Perplexity: {perp:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Optimizer\u001b[39;00m\n\u001b[0;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model_loop\u001b[38;5;241m.\u001b[39mparameters(), lr)\n\u001b[1;32m---> 11\u001b[0m train_loop(model_loop, criterion, optimizer, device)\n",
            "Cell \u001b[1;32mIn[17], line 14\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m epoch_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m epoch_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     15\u001b[0m       inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move input data to the device\u001b[39;00m\n\u001b[0;32m     16\u001b[0m       targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n",
            "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "model_loop = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "# Cross Entropy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model_loop.parameters(), lr)\n",
        "\n",
        "train_loop(model_loop, criterion, optimizer, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Salva os pesos do modelo (Treinado em Laço) e do tokenizer treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# saving the fine tuned model\n",
        "loop_path = \"model/loop\"\n",
        "model_loop.save_pretrained(loop_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Biblioteca HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Development\\conda-envs\\ml_pytorch\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f971bc9bccbb4625a4403bfaedcf45fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4633, 'grad_norm': 5.360031604766846, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.37, 'grad_norm': 3.8223471641540527, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.4}\n",
            "{'loss': 0.3632, 'grad_norm': 6.134415626525879, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.6}\n",
            "{'loss': 0.3172, 'grad_norm': 3.2651147842407227, 'learning_rate': 3.928571428571429e-05, 'epoch': 0.8}\n",
            "{'loss': 0.2884, 'grad_norm': 7.221029281616211, 'learning_rate': 3.571428571428572e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c237b2b395b4edaa8de819f71b081f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3110387325286865, 'eval_accuracy': 0.8846, 'eval_runtime': 182.5949, 'eval_samples_per_second': 27.383, 'eval_steps_per_second': 1.369, 'epoch': 1.0}\n",
            "{'loss': 0.2182, 'grad_norm': 0.07648228108882904, 'learning_rate': 3.2142857142857144e-05, 'epoch': 1.2}\n",
            "{'loss': 0.1884, 'grad_norm': 0.6571389436721802, 'learning_rate': 2.857142857142857e-05, 'epoch': 1.4}\n",
            "{'loss': 0.1835, 'grad_norm': 14.305499076843262, 'learning_rate': 2.5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.1949, 'grad_norm': 0.09540243446826935, 'learning_rate': 2.1428571428571428e-05, 'epoch': 1.8}\n",
            "{'loss': 0.1797, 'grad_norm': 3.4848520755767822, 'learning_rate': 1.785714285714286e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "075ed0e240704e45b9d02b300de33cae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.34693506360054016, 'eval_accuracy': 0.9244, 'eval_runtime': 180.5322, 'eval_samples_per_second': 27.696, 'eval_steps_per_second': 1.385, 'epoch': 2.0}\n",
            "{'loss': 0.0825, 'grad_norm': 0.028008712455630302, 'learning_rate': 1.4285714285714285e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0765, 'grad_norm': 60.4325065612793, 'learning_rate': 1.0714285714285714e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0907, 'grad_norm': 0.04618758708238602, 'learning_rate': 7.142857142857143e-06, 'epoch': 2.6}\n",
            "{'loss': 0.0639, 'grad_norm': 0.021327907219529152, 'learning_rate': 3.5714285714285714e-06, 'epoch': 2.8}\n",
            "{'loss': 0.088, 'grad_norm': 0.028519421815872192, 'learning_rate': 0.0, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd0b282b3890495bbccbb1db3a613d01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3816882371902466, 'eval_accuracy': 0.9286, 'eval_runtime': 180.5304, 'eval_samples_per_second': 27.696, 'eval_steps_per_second': 1.385, 'epoch': 3.0}\n",
            "{'train_runtime': 1996.9425, 'train_samples_per_second': 30.046, 'train_steps_per_second': 3.756, 'train_loss': 0.21122881825764975, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7500, training_loss=0.21122881825764975, metrics={'train_runtime': 1996.9425, 'train_samples_per_second': 30.046, 'train_steps_per_second': 3.756, 'train_loss': 0.21122881825764975, 'epoch': 3.0})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    save_strategy=\"epoch\",              # Do not save intermediary steps\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # Model\n",
        "    args=training_args,                  # training args\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=valid_dataset,          # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Salva os pesos do modelo (HF) e do tokenizer treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('model/hf\\\\tokenizer_config.json',\n",
              " 'model/hf\\\\special_tokens_map.json',\n",
              " 'model/hf\\\\vocab.txt',\n",
              " 'model/hf\\\\added_tokens.json',\n",
              " 'model/hf\\\\tokenizer.json')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# saving the fine tuned model\n",
        "hf_path = \"model/hf\"\n",
        "model.save_pretrained(hf_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Avaliação do Modelo (base de validação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate the current model after training\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Avaliação do Modelo (base de teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testando inferência com textos comuns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    return target_names[probs.argmax()]\n",
        "\n",
        "test_neg = \"This movie was like the worst thing ever.\"\n",
        "test_pos_1 = \"One of this generation's best\"\n",
        "test_pos_2 = \"This is a movie to die for.\"\n",
        "\n",
        "print(\"Testing predictions:\\n\")\n",
        "print(f'{test_neg} => {get_prediction(test_neg)}')\n",
        "print(f'{test_pos_1} => {get_prediction(test_pos_1)}')\n",
        "print(f'{test_pos_2} => {get_prediction(test_pos_2)}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
